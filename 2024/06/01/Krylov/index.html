<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+Simplified+Chinese:300,300italic,400,400italic,700,700italic%7CMicrosoft+YaHei:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xmq-servicecenter.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="找到了一份 优秀的课程，害怕它突然不见了，所以把目前感兴趣的内容的基本思路梳理一下。  Krylov 子空间 Krylov 子空间方法的目标是近似求解线性方程组 \[Ax&#x3D;b,\] 其中 \(A\) 是 \(n\times n\) 可逆矩阵，\(b\) 是 \(n\times1\) 的列向量。 我们将残量 \(r\) 定义为 \[r:&#x3D;b-Ax.\] Krylov 子空间方法 投影方">
<meta property="og:type" content="article">
<meta property="og:title" content="Krylov 子空间方法">
<meta property="og:url" content="https://xmq-servicecenter.github.io/2024/06/01/Krylov/index.html">
<meta property="og:site_name" content="XMQ-维修中心">
<meta property="og:description" content="找到了一份 优秀的课程，害怕它突然不见了，所以把目前感兴趣的内容的基本思路梳理一下。  Krylov 子空间 Krylov 子空间方法的目标是近似求解线性方程组 \[Ax&#x3D;b,\] 其中 \(A\) 是 \(n\times n\) 可逆矩阵，\(b\) 是 \(n\times1\) 的列向量。 我们将残量 \(r\) 定义为 \[r:&#x3D;b-Ax.\] Krylov 子空间方法 投影方">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2024-05-31T16:00:00.000Z">
<meta property="article:modified_time" content="2024-08-09T06:11:35.878Z">
<meta property="article:author" content="XMQ">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://xmq-servicecenter.github.io/2024/06/01/Krylov/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://xmq-servicecenter.github.io/2024/06/01/Krylov/","path":"2024/06/01/Krylov/","title":"Krylov 子空间方法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Krylov 子空间方法 | XMQ-维修中心</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">XMQ-维修中心</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-考前预习"><a href="/%E8%80%83%E5%89%8D%E9%A2%84%E4%B9%A0/" rel="section"><i class="fa fa-th fa-fw"></i>考前预习</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#krylov-%E5%AD%90%E7%A9%BA%E9%97%B4"><span class="nav-number">1.</span> <span class="nav-text">Krylov 子空间</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#krylov-%E5%AD%90%E7%A9%BA%E9%97%B4%E6%96%B9%E6%B3%95"><span class="nav-number">1.1.</span> <span class="nav-text">Krylov 子空间方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#arnoldi-%E8%BF%87%E7%A8%8B"><span class="nav-number">1.2.</span> <span class="nav-text">Arnoldi 过程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-gram-schmidt-%E6%AD%A3%E4%BA%A4%E5%8C%96%E7%9A%84-arnoldi-%E8%BF%87%E7%A8%8B"><span class="nav-number">1.2.1.</span> <span class="nav-text">基于 Gram-Schmidt
正交化的 Arnoldi 过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5%E7%9A%84-lanczos-%E8%BF%87%E7%A8%8B"><span class="nav-number">1.2.2.</span> <span class="nav-text">对称矩阵的 Lanczos 过程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%8C%E6%AD%A3%E4%BA%A4%E5%8C%96%E8%BF%87%E7%A8%8B%E5%8F%8C%E8%BE%B9-lanczos-%E8%BF%87%E7%A8%8B"><span class="nav-number">1.3.</span> <span class="nav-text">双正交化过程（双边 Lanczos
过程）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#krylov-%E5%AD%90%E7%A9%BA%E9%97%B4%E7%AE%97%E6%B3%95"><span class="nav-number">2.</span> <span class="nav-text">Krylov 子空间算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E6%AD%A3%E4%BA%A4%E6%96%B9%E6%B3%95fom%E9%9D%9E%E5%AF%B9%E7%A7%B0%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="nav-number">2.1.</span> <span class="nav-text">完全正交方法（FOM）：非对称线性方程组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B9%BF%E4%B9%89%E6%9E%81%E5%B0%8F%E6%AE%8B%E9%87%8F%E6%B3%95gmres%E9%9D%9E%E5%AF%B9%E7%A7%B0%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="nav-number">2.2.</span> <span class="nav-text">广义极小残量法（GMRES）：非对称线性方程组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95cg%E5%AF%B9%E7%A7%B0%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="nav-number">2.3.</span> <span class="nav-text">共轭梯度法（CG）：对称线性方程组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9E%81%E5%B0%8F%E6%AE%8B%E9%87%8F%E6%B3%95minres%E5%AF%B9%E7%A7%B0%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="nav-number">2.4.</span> <span class="nav-text">极小残量法（MINRES）：对称线性方程组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#symmlq-%E6%96%B9%E6%B3%95%E5%AF%B9%E7%A7%B0%E7%BA%BF%E6%80%A7%E6%96%B9%E7%A8%8B%E7%BB%84"><span class="nav-number">2.5.</span> <span class="nav-text">SYMMLQ 方法：对称线性方程组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E%E5%8F%8C%E6%AD%A3%E4%BA%A4%E5%8C%96%E8%BF%87%E7%A8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E7%AE%97%E6%B3%95"><span class="nav-number">2.6.</span> <span class="nav-text">基于双正交化过程的一些算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E4%B9%A6%E7%B1%8D"><span class="nav-number">3.</span> <span class="nav-text">参考书籍</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">XMQ</p>
  <div class="site-description" itemprop="description">奇怪的小网站</div>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xmq-servicecenter.github.io/2024/06/01/Krylov/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XMQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XMQ-维修中心">
      <meta itemprop="description" content="奇怪的小网站">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Krylov 子空间方法 | XMQ-维修中心">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Krylov 子空间方法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-01 00:00:00" itemprop="dateCreated datePublished" datetime="2024-06-01T00:00:00+08:00">2024-06-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-08-09 14:11:35" itemprop="dateModified" datetime="2024-08-09T14:11:35+08:00">2024-08-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>找到了一份 <a
target="_blank" rel="noopener" href="https://math.ecnu.edu.cn/~jypan/Teaching/IMP/index.html">优秀的课程</a>，害怕它突然不见了，所以把目前感兴趣的内容的基本思路梳理一下。</p>
<hr />
<h1 id="krylov-子空间">Krylov 子空间</h1>
<p>Krylov 子空间方法的目标是近似求解线性方程组 <span
class="math display">\[Ax=b,\]</span> 其中 <span
class="math inline">\(A\)</span> 是 <span class="math inline">\(n\times
n\)</span> 可逆矩阵，<span class="math inline">\(b\)</span> 是 <span
class="math inline">\(n\times1\)</span> 的列向量。</p>
<p>我们将残量 <span class="math inline">\(r\)</span> 定义为 <span
class="math display">\[r:=b-Ax.\]</span></p>
<h2 id="krylov-子空间方法">Krylov 子空间方法</h2>
<p>投影方法方法的基本思路为：选取 <span class="math inline">\(\mathbb
R^n\)</span> 的 <span class="math inline">\(m\)</span> 维子空间 <span
class="math inline">\(\mathcal K_m\)</span>，在 <span
class="math inline">\(\mathcal K_m\)</span> 中找出一个 <span
class="math inline">\(x^\ast\)</span>
作为原问题的近似解。一种最常使用的思路如下：选取 <span
class="math inline">\(\mathbb R^n\)</span> 的两个 <span
class="math inline">\(m\)</span> 维子空间 <span
class="math inline">\(\mathcal K_m\)</span> 与 <span
class="math inline">\(\mathcal L_m\)</span>，在 <span
class="math inline">\(\mathcal K_m\)</span> 中求出 <span
class="math inline">\(x^\ast\)</span> 使得： <span
class="math display">\[\begin{align}\label{orthogonal_condition}
(Ax^\ast-b) \perp \mathcal L_m.\end{align}\]</span> <span
class="math inline">\(\mathcal K_m\)</span> 称为搜索空间，<span
class="math inline">\(\mathcal L_m\)</span> 称为约束空间。</p>
<p>假设我们为线性方程组选取的初值为 <span
class="math inline">\(x_0\)</span>，<span class="math inline">\(\mathcal
K_m\)</span> 与 <span class="math inline">\(\mathcal L_m\)</span>
的一组基为 <span
class="math display">\[V_m=[v_0,v_1,\cdots,v_{m-1}],\quad
W_m=[w_0,w_1,\cdots,w_{m-1}].\]</span> 再假设 <span
class="math display">\[x^\ast=x_0+V_my,\]</span> 那么条件 (<span
class="math inline">\(\ref{orthogonal_condition}\)</span>)
实际上意味着： <span
class="math display">\[\begin{align}\label{Krylov_reduced_equation}
W_m^{\mathrm T}[A(x_0+V_my)-b]=0,\quad\text{即}\quad (W_m^{\mathrm
T}AV_m)y=W_m^{\mathrm T}(b-Ax_0).
\end{align}\]</span> <span class="math inline">\(W_m^{\mathrm
T}AV_m\)</span> 是一个 <span class="math inline">\(m\times m\)</span>
矩阵，求解这样一个 <span class="math inline">\(m\)</span>
维线性方程组就能得到原方程组的近似解。如果 <span
class="math inline">\(m\ll n\)</span>
，这一方法就对线性方程组进行了有效的降维。</p>
<p>常用的搜索空间即为 <strong>Krylov 子空间</strong>： <span
class="math display">\[\begin{align*}
\mathcal K_m(A,v):=&amp;\;\mathrm{span}\left\lbrace
v,Av,A^2v,\cdots,A^{m-1}v\right\rbrace\\
=&amp;\;\left\lbrace p(A)v:\quad
p(x)\;\text{为次数不超过}\;(m-1)\;\text{的多项式}\right\rbrace.
\end{align*}\]</span> 以 Krylov 子空间为搜索空间的迭代法就是 Krylov
子空间方法。</p>
<p>最常使用的约束空间 <span class="math inline">\(\mathcal L_m\)</span>
有三个：选取 <span class="math inline">\(\mathcal L_m=\mathcal
K_m\)</span> 时 (<span
class="math inline">\(\ref{orthogonal_condition}\)</span>) 式称为
Galerkin 条件，选取 <span class="math inline">\(\mathcal L_m=A\mathcal
K_m\)</span> 时 (<span
class="math inline">\(\ref{orthogonal_condition}\)</span>) 式称为
Petrov-Galerkin 条件，此外在 <span class="math inline">\(\mathcal
K_m=\mathcal K_m(A,v)\)</span> 时还有选取 <span
class="math inline">\(\mathcal L_m=\mathcal K_m(A^{\mathrm
T},v)\)</span> 的做法。</p>
<h2 id="arnoldi-过程">Arnoldi 过程</h2>
<p>在 Krylov 子空间中，<span
class="math inline">\(\{A^iv\}_{i=0}^m\)</span> 这组基有巨大的缺陷：随着
<span class="math inline">\(i\)</span> 的增加，<span
class="math inline">\(A^iv\)</span> 将会逐渐趋于 <span
class="math inline">\(A\)</span>
的最大特征值对应的特征向量（与幂法的思路类似），导致 <span
class="math inline">\(\{A^iv\}_{i=0}^m\)</span> 逐渐变得线性相关。为
Krylov 子空间构造一组正交基的过程就是 <strong>Arnoldi
过程</strong>。</p>
<h3 id="基于-gram-schmidt-正交化的-arnoldi-过程">基于 Gram-Schmidt
正交化的 Arnoldi 过程</h3>
<p>Arnoldi 过程的通常做法是通过 Gram-Schmidt
过程来构造这组正交基。大致算法如下：</p>
<blockquote class="colorquote pseudocode" ><p><span class="math inline">\(v_0=v/\|v\|_2\)</span><br />
for <span class="math inline">\(j=0,1,2,\cdots,(m-1):\)</span><br />
<span class="math inline">\(\quad t=Av_j\)</span><br />
<span class="math inline">\(\quad\)</span>for <span
class="math inline">\(i=0,1,2,\cdots,j:\)</span><br />
<span class="math inline">\(\quad\quad h_{i,j}=v_i^{\mathrm
T}t\)</span><br />
<span class="math inline">\(\quad\quad t=t-h_{i,j}v_i\)</span><br />
<span class="math inline">\(\quad\)</span>endfor<br />
<span class="math inline">\(\quad h_{j+1,j}=\|t\|_2\)</span><br />
<span class="math inline">\(\quad\)</span>if <span
class="math inline">\(h_{j+1,j}==0\)</span>:<br />
<span class="math inline">\(\quad\quad\)</span>break<br />
<span class="math inline">\(\quad\)</span>else:<br />
<span class="math inline">\(\quad\quad
v_{j+1}=t/h_{j+1,j}\)</span><br />
endfor</p>
</blockquote>
<p>不难证明，以上算法给出：</p>
<p><span class="math display">\[\begin{align*}
AV_m=&amp;\;V_mH_m+v_m[0,\;0,\;0,\;\cdots,\;0,\;h_{m,m-1}]_{1\times
m},\\
=&amp;\;V_{m+1}H_{m+1,m}.
\end{align*}\]</span></p>
<p>其中 <span class="math inline">\(V_m\)</span> 就是 Krylov
子空间的正交归一基，<span class="math inline">\(H_m\)</span> 是 <span
class="math inline">\(m\times m\)</span> 的上 Hessenberg 矩阵，<span
class="math inline">\(H_{m+1,m}\)</span> 是 <span
class="math inline">\((m+1)\times m\)</span> 的上 Hessenberg 矩阵，并且
<span class="math inline">\(H_m\)</span> 是 <span
class="math inline">\(H_{m+1}\)</span> 的前 <span
class="math inline">\(m\)</span> 行： <span
class="math display">\[\begin{align}\begin{split}
V_m:=&amp;\;[v_0,\;v_1,\;\cdots,\;v_{m-1}],\\
H_{m}:=&amp;\;\begin{bmatrix}
h_{0,0}&amp;h_{0,1}&amp;h_{0,2}&amp;\cdots&amp;h_{0,m-2}&amp;h_{0,m-1}\\
h_{1,0}&amp;h_{1,1}&amp;h_{1,2}&amp;\cdots&amp;h_{1,m-2}&amp;h_{1,m-1}\\
0      &amp;h_{2,1}&amp;h_{2,2}&amp;\cdots&amp;h_{2,m-2}&amp;h_{2,m-1}\\
0      &amp;0      &amp;h_{3,2}&amp;\cdots&amp;h_{3,m-2}&amp;h_{3,m-1}\\
\vdots &amp;\vdots &amp;\vdots &amp;      &amp;\vdots   &amp;\vdots \\
0      &amp;0      &amp;0&amp;\cdots&amp;h_{m-1,m-2}&amp;h_{m-1,m-1}\\
\end{bmatrix},\\
H_{m+1,m}:=&amp;\;\begin{bmatrix}
h_{0,0}&amp;h_{0,1}&amp;h_{0,2}&amp;\cdots&amp;h_{0,m-2}&amp;h_{0,m-1}\\
h_{1,0}&amp;h_{1,1}&amp;h_{1,2}&amp;\cdots&amp;h_{1,m-2}&amp;h_{1,m-1}\\
0      &amp;h_{2,1}&amp;h_{2,2}&amp;\cdots&amp;h_{2,m-2}&amp;h_{2,m-1}\\
0      &amp;0      &amp;h_{3,2}&amp;\cdots&amp;h_{3,m-2}&amp;h_{3,m-1}\\
\vdots &amp;\vdots &amp;\vdots &amp;      &amp;\vdots   &amp;\vdots \\
0      &amp;0      &amp;0&amp;\cdots&amp;h_{m-1,m-2}&amp;h_{m-1,m-1}\\
0      &amp;0      &amp;0&amp;\cdots&amp;0&amp;h_{m,m-1}\\
\end{bmatrix}.
\end{split}\end{align}\]</span></p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>Gram-Schmidt 正交化算法给出： <span
class="math display">\[h_{j+1,j}v_{j+1}=Av_j-(h_{0,j}v_0+h_{1,j}v_1+h_{2,j}v_2+\cdots+h_{j,j}v_j),\]</span>
即 <span
class="math display">\[Av_j=(h_{0,j}v_0+h_{1,j}v_1+h_{2,j}v_2+\cdots+h_{j,j}v_j)+h_{j+1,j}v_{j+1}.\]</span>
写为矩阵形式就是： <span
class="math display">\[A[v_0,\;v_1,\;\cdots,\;v_{m-1}]=[v_0,\;v_1,\;\cdots,\;v_{m-1},\;v_{m}]H_{m+1,m}.\]</span>
我们可以把 <span class="math inline">\(v_m\)</span> 单独拿出： <span
class="math display">\[A[v_0,\;v_1,\;\cdots,\;v_{m-1}]=[v_0,\;v_1,\;\cdots,\;v_{m-1}]H_{m}+v_m[0,\;0,\;0,\;\cdots,\;0,\;h_{m,m-1}]_{1\times
m}.\]</span> 这里的 <span class="math inline">\(H_{m}\)</span> 为 <span
class="math inline">\(H_{m+1,m}\)</span> 的前 <span
class="math inline">\(m\)</span> 行。我们再将 <span
class="math inline">\([v_0,\;v_1,\;\cdots,\;v_{m-1}]\)</span> 记为 <span
class="math inline">\(V_m\)</span>。就有： <span
class="math display">\[AV_m=V_mH_m+v_m[0,\;0,\;0,\;\cdots,\;0,\;h_{m,m-1}]_{1\times
m}.\]</span></p>

    </div>
</div>
<p>不难看出，如果 <span class="math inline">\(h_{m,m-1}=0\)</span>，那么
<span class="math inline">\(v_0\sim v_{m-1}\)</span> 将构成 <span
class="math inline">\(A\)</span> 的一个不变子空间。</p>
<p>由于 <span class="math inline">\(v_0\sim v_m\)</span> 彼此正交，即
<span class="math inline">\(V_m^{\mathrm T}V_m=I_m\)</span>，所以：
<span class="math display">\[\begin{align}\label{VAV}
V_m^{\mathrm T}AV_m=H_m.
\end{align}\]</span></p>
<h3 id="对称矩阵的-lanczos-过程">对称矩阵的 Lanczos 过程</h3>
<p>如果 <span class="math inline">\(A\)</span> 是对称矩阵，从 (<span
class="math inline">\(\ref{VAV}\)</span>) 式可以看出 <span
class="math inline">\(H_m\)</span> 也是对称矩阵，这意味着 <span
class="math inline">\(H_m\)</span> 是三对角矩阵。</p>
<p>此时，Arnoldi 过程中的正交化步骤可得到有效的简化： <span
class="math display">\[\begin{align*}h_{j+1,j}v_{j+1}=&amp;\;Av_j-(h_{0,j}v_0+h_{1,j}v_1+h_{2,j}v_2+\cdots+h_{j,j}v_j)\\
=&amp;\;Av_j-(h_{j-1,j}v_{j-1}+h_{j,j}v_j).\end{align*}\]</span></p>
<h2 id="双正交化过程双边-lanczos-过程">双正交化过程（双边 Lanczos
过程）</h2>
<p>双正交化过程与 Arnoldi 过程不同，它可为 <span
class="math inline">\(\mathcal K_m=\mathcal K_m(A,v)\)</span> 与 <span
class="math inline">\(\mathcal L_m=\mathcal K_m(A^{\mathrm
T},w)\)</span> 分别找到一组不正交的基 <span
class="math inline">\(V_m:=[v_0,\;\cdots,\;v_{m-1}]\)</span> 与 <span
class="math inline">\(W_m:=[w_0,\;\cdots,\;w_{m-1}]\)</span>，使它们满足：
<span class="math display">\[v_i^{\mathrm
T}w_j=\delta_{ij}.\]</span></p>
<p>在双正交过程中，计算 <span class="math inline">\(v_i\)</span> 与
<span class="math inline">\(w_i\)</span> 的递推关系为： <span
class="math display">\[\begin{align*}
\gamma_kv_{k+1}=&amp;\;Av_k-\alpha_kv_k-\beta_{k-1}v_{k-1},\\
\beta_kw_{k+1}=&amp;\;A^{\mathrm T}w_k-\alpha_kw_k-\gamma_{k-1}w_{k-1},
\end{align*}\]</span> 其中 <span
class="math display">\[\alpha_k=w_k^{\mathrm T}Av_k,\quad
\beta_{-1}=\gamma_{-1}=0,\quad
\beta_k,\gamma_k(k\geqslant0)\;\text{可任取只需保证}\;v_{k+1}^{\mathrm
T}w_{k+1}=1.\]</span> 用数学归纳法可以证明这样得到的基确实能够满足 <span
class="math inline">\(v_i^{\mathrm T}w_j=\delta_{ij}\)</span>。</p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p><span class="math inline">\(k=0\)</span> 时 <span
class="math inline">\(v_0^{\mathrm T}w_0=1\)</span> 成立。</p>
<p>假设 <span class="math inline">\(i\leqslant k\)</span>，<span
class="math inline">\(j\leqslant k\)</span> 时有 <span
class="math inline">\(v_i^{\mathrm T}w_j=\delta_{ij}\)</span>。由于
<span class="math inline">\(\gamma_k\beta_k\)</span> 的选择使得 <span
class="math inline">\(v_{k+1}^{\mathrm
T}w_{k+1}=1\)</span>，所以只需要证明对 <span class="math inline">\(0\sim
k\)</span> 中的任意一个 <span class="math inline">\(i\)</span> 都有
<span class="math inline">\(v_{k+1}^{\mathrm T}w_{i}=v_{i}^{\mathrm
T}w_{k+1}=0\)</span> 即可。</p>
<p>如果 <span class="math inline">\(i\leqslant k-2\)</span>，那么 <span
class="math inline">\(v_{k+1}^{\mathrm T}w_i=0\)</span>： <span
class="math display">\[\begin{align*}\gamma_kv_{k+1}^{\mathrm
T}w_i=&amp;\;(v_k^{\mathrm T}A^{\mathrm
T}w_i)-(\alpha_kv_k+\beta_{k-1}v_{k-1})^{\mathrm T}w_i\\
=&amp;\;v_k^{\mathrm
T}(\beta_iw_{i+1}+\alpha_iw_i+\gamma_{i-1}w_{i-1})-0\\
=&amp;\;0,\end{align*}\]</span> 同理可证 <span
class="math inline">\(i\leqslant k-2\)</span> 时 <span
class="math inline">\(v_i^{\mathrm T}w_{k+1}=0\)</span>。</p>
<p><span class="math inline">\(i=k-1\)</span> 时： <span
class="math display">\[\begin{align*}\gamma_kv_{k+1}^{\mathrm
T}w_{k-1}=&amp;\;(v_k^{\mathrm T}A^{\mathrm
T}w_{k-1})-(\alpha_kv_k+\beta_{k-1}v_{k-1})^{\mathrm T}w_{k-1}\\
=&amp;\;v_k^{\mathrm
T}(\beta_{k-1}w_{k}+\alpha_{k-1}w_{k-1}+\gamma_{k-2}w_{k-2})-\beta_{k-1}v_{k-1}^{\mathrm
T}w_{k-1}\\
=&amp;\;\beta_{k-1}-\beta_{k-1}=0,\end{align*}\]</span> 同理可证 <span
class="math inline">\(\beta_kv_{k-1}^{\mathrm T}w_{k+1}=0\)</span>.</p>
<p><span class="math inline">\(i=k\)</span> 时： <span
class="math display">\[\begin{align*}\gamma_kv_{k+1}^{\mathrm
T}w_k=&amp;\;(v_k^{\mathrm T}A^{\mathrm
T}w_k)-(\alpha_kv_k+\beta_{k-1}v_{k-1})^{\mathrm T}w_k\\
=&amp;\;(v_k^{\mathrm T}A^{\mathrm T}w_k)-\alpha_k\\
=&amp;\;0.\end{align*}\]</span> 同理可证 <span
class="math inline">\(\beta_kv_{k}^{\mathrm T}w_{k+1}=0\)</span>.</p>
<p>这样就完成了证明。</p>

    </div>
</div>
<p>相应的算法是：</p>
<blockquote class="colorquote pseudocode" ><p><span class="math inline">\(v_0=v/\|v\|_2\)</span><br />
<span class="math inline">\(w_0=\|v\|_2w/(v^{\mathrm T}w)\)</span><br />
for <span class="math inline">\(j=0,1,2,\cdots,(m-1):\)</span><br />
<span class="math inline">\(\quad \tilde
v_{j+1}=Av_j-\beta_{j-1}v_{j-1}\)</span><br />
<span class="math inline">\(\quad \tilde
w_{j+1}=Aw_j-\gamma_{j-1}w_{j-1}\)</span><br />
<span class="math inline">\(\quad \alpha_j=v_j^{\mathrm T}\tilde
w_{j+1}\)</span><br />
<span class="math inline">\(\quad \tilde v_{j+1}=\tilde
v_{j+1}-\alpha_jv_j\)</span><br />
<span class="math inline">\(\quad \tilde w_{j+1}=\tilde
w_{j+1}-\alpha_jw_j\)</span><br />
<span class="math inline">\(\quad \gamma_j=\sqrt{|\tilde
v_{j+1}^{\mathrm T}\tilde w_{j+1}|}\)</span><br />
<span class="math inline">\(\quad\)</span>if <span
class="math inline">\(\gamma_j==0\)</span>:<br />
<span class="math inline">\(\quad\quad\)</span>break<br />
<span class="math inline">\(\quad\)</span>else:<br />
<span class="math inline">\(\quad\quad \beta_j=(\tilde v_{j+1}^{\mathrm
T}\tilde w_{j+1})/\gamma_j\)</span><br />
<span class="math inline">\(\quad\quad v_{j+1}=\tilde
v_{j+1}/\gamma_j\)</span><br />
<span class="math inline">\(\quad\quad w_{j+1}=\tilde
w_{j+1}/\beta_j\)</span><br />
<span class="math inline">\(\quad\)</span>endif<br />
endfor</p>
</blockquote>
<p>不难验证，这一算法给出：</p>
<p><span class="math display">\[\begin{align*}
AV_m=&amp;\;V_{m+1}T^{(1)}_{m+1,m}=V_mT_m+v_m[0,\;0,\;0,\;\cdots,\;0,\;\gamma_{m-1}]_{1\times
m},\\
A^{\mathrm T}W_m=&amp;\;W_{m+1}T^{(2)}_{m+1,m}=W_mT_m^{\mathrm
T}+w_m[0,\;0,\;0,\;\cdots,\;0,\;\beta_{m-1}]_{1\times m}.
\end{align*}\]</span></p>
<p>其中 <span class="math inline">\(V_m\)</span> 与 <span
class="math inline">\(W_m\)</span> 就是 <span
class="math inline">\(\mathcal K\)</span> 与 <span
class="math inline">\(\mathcal L_m\)</span> 的一组基且满足 <span
class="math inline">\(V_m^{\mathrm T}W_m=I_m\)</span>，<span
class="math inline">\(T_m\)</span> 是 <span
class="math inline">\(m\times m\)</span> 的三对角矩阵，<span
class="math inline">\(T_{m+1,m}\)</span> 是 <span
class="math inline">\((m+1)\times m\)</span> 的上 Hessenberg 矩阵，且
<span class="math inline">\(T_m\)</span> 是 <span
class="math inline">\(T_{m+1}\)</span> 的前 <span
class="math inline">\(m\)</span> 行：</p>
<p><span class="math display">\[\begin{align}\begin{split}
V_m:=&amp;\;[v_0,\;v_1,\;\cdots,\;v_{m-1}],\\
W_m:=&amp;\;[w_0,\;w_1,\;\cdots,\;w_{m-1}],\\
T_{m}:=&amp;\;\begin{bmatrix}
\alpha_0&amp;\beta_0&amp;&amp;&amp;\\
\gamma_0&amp;\alpha_1&amp;\beta_1&amp;&amp;\\
&amp;\gamma_1&amp;\alpha_2&amp;\ddots&amp;\\
&amp;&amp;\ddots&amp;\ddots&amp;\beta_{m-2}\\
&amp;&amp;&amp;\gamma_{m-2}&amp;\alpha_{m-1}\\
\end{bmatrix},\\
T_{m+1,m}^{(1)}:=&amp;\;\begin{bmatrix}
\alpha_0&amp;\beta_0&amp;&amp;&amp;\\
\gamma_0&amp;\alpha_1&amp;\beta_1&amp;&amp;\\
&amp;\gamma_1&amp;\alpha_2&amp;\ddots&amp;\\
&amp;&amp;\ddots&amp;\ddots&amp;\beta_{m-2}\\
&amp;&amp;&amp;\gamma_{m-2}&amp;\alpha_{m-1}\\
&amp;&amp;&amp; &amp;\gamma_{m-1}\\
\end{bmatrix},\\
T_{m+1,m}^{(2)}:=&amp;\;\begin{bmatrix}
\alpha_0&amp;\gamma_0&amp;&amp;&amp;\\
\beta_0&amp;\alpha_1&amp;\gamma_1&amp;&amp;\\
&amp;\beta_1&amp;\alpha_2&amp;\ddots&amp;\\
&amp;&amp;\ddots&amp;\ddots&amp;\gamma_{m-2}\\
&amp;&amp;&amp;\beta_{m-2}&amp;\alpha_{m-1}\\
&amp;&amp;&amp; &amp;\beta_{m-1}\\
\end{bmatrix}.
\end{split}\end{align}\]</span></p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>只需注意到双正交过程给出的递推关系是：</p>
<p><span class="math display">\[\begin{align*}
Av_k=&amp;\;\gamma_kv_{k+1}+\alpha_kv_k+\beta_{k-1}v_{k-1},\\
A^{\mathrm T}w_k=&amp;\;\beta_kw_{k+1}+\alpha_kw_k+\gamma_{k-1}w_{k-1},
\end{align*}\]</span> 其中 <span
class="math inline">\(\beta_{-1}=\gamma_{-1}=0\)</span>。</p>

    </div>
</div>
<p>以上结果告诉我们： <span
class="math display">\[\begin{align}\label{WAV}
W_m^{\mathrm T}AV_m=T_m.
\end{align}\]</span></p>
<p>双正交化过程的优点在于计算量相对 Arnoldi 过程较低，因为构造 <span
class="math inline">\(v_{k+1}\)</span> 与 <span
class="math inline">\(w_{k+1}\)</span> 时只需要考虑 <span
class="math inline">\(i=k-1,k\)</span> 时的 <span
class="math inline">\(v_i\)</span> 与 <span
class="math inline">\(w_i\)</span>。但其问题是这样构造出的 <span
class="math inline">\(v_i\)</span> 之间并不正交，并且容易中断。</p>
<h1 id="krylov-子空间算法">Krylov 子空间算法</h1>
<p>以下主要说明基于 Arnoldi
过程的算法。基于双正交过程的算法留在这一部分的最后一小节。</p>
<p>在以下所有算法中，我们都定义 <span
class="math display">\[\beta:=\|b-Ax_0\|_2.\]</span></p>
<p>对于那些基于 Arnoldi 过程的算法，我们将 <span
class="math inline">\((b-Ax_0)\)</span>——即初值 <span
class="math inline">\(x_0\)</span> 给出的剩余向量——作为 Arnoldi
过程的初值，并计算出 <span
class="math inline">\(V_m=[v_0,v_1,\cdots,v_{m-1}]\)</span>，<span
class="math inline">\(H_m\)</span>，以及 <span
class="math inline">\(H_{m+1,m}\)</span>。</p>
<p>我们还用 <span class="math inline">\(e_i\)</span> 表示只有第 <span
class="math inline">\(i\)</span> 个元素为 <span
class="math inline">\(1\)</span> 其余元素为 <span
class="math inline">\(0\)</span>
的列向量（总长度不固定）。此时，初值的剩余向量可以写为 <span
class="math display">\[b-Ax_0=\beta v_0=\beta V_me_1=\beta
V_{m+1}e_1.\]</span></p>
<h2
id="完全正交方法fom非对称线性方程组">完全正交方法（FOM）：非对称线性方程组</h2>
<p><strong>完全正交方法（Full Orthogonalization Method）</strong>
可用于并不对称的 <span class="math inline">\(A\)</span>。FOM 取约束空间
<span class="math inline">\(\mathcal L_m=\mathcal K_m\)</span>，并用
Arnoldi 过程找出 <span class="math inline">\(\mathcal K_m\)</span> 与
<span class="math inline">\(\mathcal L_m\)</span> 的一组基。此时的条件
(<span class="math inline">\(\ref{Krylov_reduced_equation}\)</span>)——即
<span class="math inline">\((W_m^{\mathrm T}AV_m)y=W_m^{\mathrm
T}(b-Ax_0)\)</span>——变为： <span class="math display">\[(V_m^{\mathrm
T}AV_m)y=V_m^{\mathrm T}(b-Ax_0).\]</span> 由 (<span
class="math inline">\(\ref{VAV}\)</span>) 以及 <span
class="math inline">\(v_0\sim v_{m-1}\)</span> 之间的正交性可得： <span
class="math display">\[H_my=\beta e_1.\]</span> 求出这一 <span
class="math inline">\(m\)</span> 维线性方程组的解 <span
class="math inline">\(y_m\)</span> 就能通过 <span
class="math inline">\(x^\ast_m=x_0+V_my_m\)</span> 得到 <span
class="math inline">\(x^\ast\)</span> 的估计，这就是 FOM
的基本思路。</p>
<p>实际计算时，会逐渐增加 <span class="math inline">\(m\)</span>，直到
<span class="math inline">\(b-Ax^\ast_m\)</span>
变得足够小。在这一过程中，前面算出的 <span
class="math inline">\(v_i\)</span> 与 <span
class="math inline">\(H_m\)</span> 可以保存下来。</p>
<h2
id="广义极小残量法gmres非对称线性方程组">广义极小残量法（GMRES）：非对称线性方程组</h2>
<p><strong>广义极小残量法（Generalized Minimum Residual）</strong>
可用于并不对称的 <span class="math inline">\(A\)</span>。GMRES
取约束空间 <span class="math inline">\(\mathcal L_m=A\mathcal
K_m\)</span>，并用 Arnoldi 过程找出 <span class="math inline">\(\mathcal
K_m\)</span> 的一组基。此时的条件 (<span
class="math inline">\(\ref{Krylov_reduced_equation}\)</span>)——即 <span
class="math inline">\((W_m^{\mathrm T}AV_m)y=W_m^{\mathrm
T}(b-Ax_0)\)</span>——变为： <span class="math display">\[(V_m^{\mathrm
T}A^{\mathrm T}AV_m)y=V_m^{\mathrm T}A^{\mathrm T}(b-Ax_0).\]</span>
这一方程实际上就是最小二乘问题 <span
class="math inline">\(\displaystyle\min_{y\in \mathbb
R^m}\|AV_my-b+Ax_0\|^2_2\)</span>，即 <span
class="math display">\[\displaystyle\min_{x\in x_0+\mathcal
K_m}\|Ax-b\|^2_2\]</span> 的解，这就是广义极小残量法的名称来源。</p>
<p>由于 <span class="math display">\[\begin{align*}\begin{split}
AV_my-b+Ax_0=&amp;\;V_{m+1}H_{m+1,m}y-\beta v_0\\
=&amp;\;V_{m+1}H_{m+1,m}y-\beta V_{m+1}e_1,
\end{split}\end{align*}\]</span></p>
<p>再加 <span class="math inline">\(V_{m+1}^{\mathrm
T}V_{m+1}=I_{m+1}\)</span>，就能发现 <span
class="math display">\[\displaystyle\min_{x\in x_0+\mathcal
K_m}\|Ax-b\|^2_2=\displaystyle\min_{y\in \mathbb R^m}\|H_{m+1,m}y-\beta
e_1\|^2_2.\]</span> 由于 <span class="math inline">\(H_{m+1,m}\)</span>
是上 Hessenberg 矩阵，并且维数不高，所以这一最小二乘问题可以用 QR
分解求解。这就是 GMRES 的基本思路。</p>
<p>在对 <span class="math inline">\(H_{m+1,m}\)</span> 做 QR
分解时可采用 Givens 变换。由于</p>
<ul>
<li><span class="math inline">\(H_{m+2,m+1}\)</span>
中对角线以下的元素的数目相较于 <span
class="math inline">\(H_{m+1,m}\)</span> 仅仅只多了 <span
class="math inline">\(1\)</span> 个，</li>
<li><span class="math inline">\(H_{m+1,m}\)</span> 是 <span
class="math inline">\(H_{m+2,m+1}\)</span> 的子矩阵，</li>
</ul>
<p>所以要完成 <span class="math inline">\(H_{m+2,m+1}\)</span> 的 QR
分解，就只需要在 <span class="math inline">\(H_{m+1,m}\)</span> 的 QR
分解的基础上再加一次 Givens 变换即可。存储的时候只需要记录下 Givens
变换即可，甚至可以将 QR 分解得到的 <span
class="math inline">\(R\)</span> 存储在 <span
class="math inline">\(H\)</span> 中。</p>
<p>当迭代次数过多，即 <span class="math inline">\(m\)</span>
过大时，存储量会很大，此时可以采取重启策略。即当 <span
class="math inline">\(m\)</span> 达到 <span
class="math inline">\(20\sim50\)</span>
时，以最后一步的结果作为初值，重新开始 GMRES 方法。</p>
<h2
id="共轭梯度法cg对称线性方程组">共轭梯度法（CG）：对称线性方程组</h2>
<p>如果 <span class="math inline">\(A\)</span> 是对称正定矩阵，那么
<span class="math inline">\(Ax=b\)</span> 可通过
<strong>共轭梯度法（Conjugate Gradient, CG）</strong>
求解。接下来我们证明，共轭梯度法本质上就是 FOM，即 <span
class="math inline">\(\mathcal L_m=\mathcal K_m\)</span> 且用 Arnoldi
过程寻找 <span class="math inline">\(\mathcal K_m\)</span> 的一组基的
Krylov 子空间算法。</p>
<p>我们将 FOM 的每一步迭代产生的估计 <span
class="math inline">\(x_m\)</span> 写出：</p>
<p><span class="math display">\[\begin{align*}
x_m=&amp;\;x_0+V_my_m=x_0+V_m(H_m^{-1}\beta e_1).
\end{align*}\]</span> 由于 <span class="math inline">\(A\)</span>
是对称正定矩阵，所以 <span class="math inline">\(H_m=V_m^{\mathrm
T}AV_m\)</span> 也是对称正定矩阵，我们可以对 <span
class="math inline">\(H_m\)</span> 做 <span
class="math inline">\(LDL^{\mathrm T}\)</span> 分解： <span
class="math display">\[\begin{align}\label{H=LDL}
H_m=L_mD_mL_m^{\mathrm T}=
\begin{bmatrix}
1&amp;&amp;&amp;\\
l_1&amp;1&amp;&amp;\\
&amp;\ddots&amp;\ddots&amp;\\
&amp;&amp;l_{m-1}&amp;1
\end{bmatrix}
\begin{bmatrix}
d_0&amp;&amp;&amp;\\
&amp;d_1&amp;&amp;\\
&amp;&amp;\ddots&amp;\\
&amp;&amp;&amp;d_{m-1}
\end{bmatrix}
\begin{bmatrix}
1&amp;l_1&amp;&amp;\\
&amp;1&amp;\ddots&amp;\\
&amp;&amp;\ddots&amp;l_{m-1}\\
&amp;&amp;&amp;1
\end{bmatrix}
.\end{align}\]</span> 其中： <span
class="math display">\[d_0=h_{0,0},\quad l_i=h_{i-1,i}/d_{i-1},\quad
d_i=h_{i,i}-l_ih_{i-1,i}\quad(i&gt;0).\]</span></p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p><span class="math display">\[\begin{align*}
(L_mD_m)L_m^{\mathrm T}=&amp;\;\begin{bmatrix}
d_0&amp;&amp;&amp;&amp;\\
l_1d_0&amp;d_1&amp;&amp;&amp;\\
&amp;l_2d_1&amp;d_2&amp;&amp;\\[1em]
&amp;&amp;\ddots&amp;\ddots&amp;\\[1em]
&amp;&amp;&amp;l_{m-1}d_{m-2}&amp;d_{m-1}
\end{bmatrix}\begin{bmatrix}
1&amp;l_1&amp;&amp;\\
&amp;1&amp;\ddots&amp;\\
&amp;&amp;\ddots&amp;l_{m-1}\\
&amp;&amp;&amp;1
\end{bmatrix}\\
=&amp;\;\begin{bmatrix}
d_0&amp;l_1d_0&amp;&amp;&amp;\\
l_1d_0&amp;d_1+l_1^2d_0&amp;l_2d_1&amp;&amp;\\
&amp;l_2d_1&amp;d_2+l_2^2d_1&amp;\ddots&amp;\\[1em]
&amp;&amp;\ddots&amp;\ddots&amp;l_{m-1}d_{m-2}\\[1em]
&amp;&amp;&amp;l_{m-1}d_{m-2}&amp;d_{m-1}+l_{m-1}^2d_{m-2}
\end{bmatrix}
\end{align*}\]</span> 因此 <span
class="math display">\[h_{0,0}=d_0,\quad h_{j-1,j}=l_jd_{j-1},\quad
h_{j,j}=d_j+l_j^2d_{j-1}=d_j+l_jh_{j-1,j}\quad (j&gt;0).\]</span></p>

    </div>
</div>
<p>我们将 <span class="math inline">\((L_m^{\mathrm T})^{-1}\)</span>
简记为 <span class="math inline">\(L_m^{-\mathrm T}\)</span>，那么 <span
class="math display">\[\begin{align*}
x_m=&amp;\;x_0+V_my_m=x_0+(V_mL_m^{-\mathrm T})(\beta
D_m^{-1}L_m^{-1}e_1)\\
:=&amp;\;x_0+\tilde P_m\tilde y_m,
\end{align*}\]</span> 其中 <span class="math inline">\(\tilde
P_m:=V_mL_m^{-\mathrm T}\)</span>，<span class="math inline">\(\tilde
y_m=\beta D_m^{-1}L_m^{-1}e_1\)</span>。再假设 <span
class="math display">\[\tilde P_m:=[\tilde p_0,\tilde p_1,\cdots,\tilde
p_{m-1}],\quad \tilde y_m:=[\eta_0,\eta_1,\cdots,\eta_{m-1}]^{\mathrm
T}.\]</span> 那么 <span class="math display">\[x_{m+1}=x_0+\tilde
P_{m+1}\tilde y_{m+1}=x_0+\tilde P_{m}\tilde y_{m}+\eta_m\tilde
p_{m}=x_m+\eta_m\tilde p_{m}.\]</span></p>
<p>我们可以证明 <span class="math inline">\(\tilde P_m^{\mathrm
T}A\tilde P_m\)</span> 是对角矩阵： <span class="math display">\[\tilde
P_m^{\mathrm T}A\tilde P_m=L_m^{-1}V_m^{\mathrm T}AV_mL_m^{-\mathrm
T}=L_m^{-1}H_mL_m^{-\mathrm T}=D_m,\]</span> 这意味着 <span
class="math inline">\(\tilde P_m\)</span> 的列向量，即 <span
class="math inline">\(\tilde p_m\)</span> 是 <span
class="math inline">\(A\)</span>-正交的。</p>
<p><span class="math inline">\(\tilde p_{m}\)</span> 的具体形式是：
<span class="math display">\[\begin{align*}
[\tilde p_0,\tilde p_1,\cdots,\tilde
p_{m-1}]=&amp;\;[v_0,v_1,\cdots,v_{m-1}]\begin{bmatrix}
1&amp;-l_1&amp;&amp;\\
&amp;1&amp;\ddots&amp;\\
&amp;&amp;\ddots&amp;-l_{m-1}\\
&amp;&amp;&amp;1
\end{bmatrix}\\
=&amp;\;[v_0,v_1-l_1v_0,\cdots,v_{m-1}-l_{m-1}v_{m-2}].\end{align*}\]</span></p>
<p>考虑到：</p>
<ul>
<li><span class="math inline">\(\tilde p_0=\tilde
v_0\)</span>，这与共轭梯度法一致。</li>
<li><span class="math inline">\(\tilde
p_m=v_{m}-l_{m}v_{m-1}\)</span>，这意味着 <span
class="math inline">\(\tilde p_m\)</span> 由 <span
class="math inline">\(v_0\sim v_m\)</span> 生成，也就是由 <span
class="math inline">\(A^0v_0\sim A^mv_0\)</span>
生成。这与共轭梯度法一致。</li>
<li>迭代的每一步都沿着互相 <span
class="math inline">\(A\)</span>-正交的方向，这与共轭梯度法一致。</li>
<li>当 <span
class="math inline">\(m=n\)</span>，即搜索空间的维数等于原线性方程组的维数时，<span
class="math inline">\(x_m\)</span>
就是原方程组的解，这与共轭梯度法一致。</li>
</ul>
<p>所以通过 FOM 方法产生的序列 <span
class="math inline">\(\{x_k\}_{k=0}^n\)</span>
与共轭梯度法产生的序列一样，因此 FOM 等价于共轭梯度法。</p>
<h2
id="极小残量法minres对称线性方程组">极小残量法（MINRES）：对称线性方程组</h2>
<p>CG 只适用于 <span class="math inline">\(A\)</span>
对称正定的情形，<span class="math inline">\(A\)</span>
不定时可用<strong>极小残量法（MINRES）</strong>，它是 GMRES
在对称情形下的特例。由于 <span class="math inline">\(A\)</span>
是对称的，所以 <span class="math inline">\(H_m\)</span>
是三对角矩阵，通过 Givens 变换做 QR 分解时可以有相当程度的简化。</p>
<h2 id="symmlq-方法对称线性方程组">SYMMLQ 方法：对称线性方程组</h2>
<p>SYMMLQ 方法与 CG 或 FOM 一样，取 <span class="math inline">\(\mathcal
L_m=\mathcal K_m\)</span>，并用 Arnoldi 过程为 <span
class="math inline">\(\mathcal K_m\)</span> 找出一组基。它在 <span
class="math inline">\(A\)</span> 为对称正定时等价于 CG，但也可用于处理
<span class="math inline">\(A\)</span> 不定的情形。</p>
<p>在 <span class="math inline">\(A\)</span> 不定时，(<span
class="math inline">\(\ref{H=LDL}\)</span>) 式的 <span
class="math inline">\(LDL^{\mathrm T}\)</span> 分解不一定存在（因为
<span class="math inline">\(D\)</span> 中的 <span
class="math inline">\(d_i\)</span> 可能为 <span
class="math inline">\(0\)</span> 导致算法无法推进）。此时，可以对 <span
class="math inline">\(H_m\)</span> 做 LQ 分解（与 QR 分解类似）： <span
class="math display">\[H_m=\tilde L_mQ_m\]</span> <span
class="math inline">\(\tilde L_m\)</span> 是下三角矩阵，<span
class="math inline">\(Q_m\)</span> 是正交矩阵。</p>
<p>基于这一分解，FOM 方法产生的序列为： <span
class="math display">\[\begin{align*}
x_m=&amp;\;x_0+V_my_m=x_0+V_m(H_m^{-1}\beta e_1)\\
=&amp;\;x_0+(V_mQ_m^{\mathrm T})(L_m^{-1}\beta e_1).
\end{align*}\]</span></p>
<p><span class="math inline">\(H_m\)</span> 是三对角矩阵，所以 <span
class="math inline">\(H_m\)</span> 的 LQ 分解可通过 Givens
变换完成，并且 <span class="math inline">\(H_{m+1}\)</span> 的 LQ
分解相较于 <span class="math inline">\(H_m\)</span> 而言只多了一次
Givens 变换。由此可构建递推关系。</p>
<h2 id="基于双正交化过程的一些算法">基于双正交化过程的一些算法</h2>
<p>在基于双正交化过程的算法中，类似于 FOM
的方法是双共轭梯度法（BiCG），类似于 GMRES 的方法是 QMR 方法。</p>
<p>双正交化过程通常都会将 <span
class="math inline">\(b-Ax_0\)</span>——即初值的残量——作为 <span
class="math inline">\(\beta v_0\)</span>，其中 <span
class="math inline">\(\beta:=\|b-Ax_0\|_2\)</span>，然后再任选一个不与
<span class="math inline">\(v_0\)</span> 正交的向量作为 <span
class="math inline">\(w_0\)</span>（通常也选为 <span
class="math inline">\(v_0\)</span>）。选定这两个初值后，经过双正交化过程就能得到
<span class="math inline">\(V_m\)</span>，<span
class="math inline">\(W_m\)</span> 以及 <span
class="math inline">\(T_m\)</span>。</p>
<p>BiCG 方法中，条件 (<span
class="math inline">\(\ref{Krylov_reduced_equation}\)</span>)——即 <span
class="math inline">\((W_m^{\mathrm T}AV_m)y=W_m^{\mathrm
T}(b-Ax_0)\)</span>——变为： <span class="math display">\[T_my=\beta
e_1.\]</span> 这是一个三对角线性方程组。可以证明，当 <span
class="math inline">\(A\)</span> 对称正定且 <span
class="math inline">\(w_0=v_0\)</span>
时它等价于共轭梯度法。但在很多情况下，BiCG 的稳定性并不很好。</p>
<p>QMR 算法与 GMRES 一样考虑如下最小二乘问题： <span
class="math display">\[\displaystyle\min_{x\in x_0+\mathcal
K_m}\|Ax-b\|^2_2.\]</span> 但在 QMR 算法中： <span
class="math display">\[\begin{align*}
b-Ax=&amp;\;b-A(x_0+V_my)=\beta v_0-AV_my\\
=&amp;\;\beta v_0-V_{m+1}T^{(1)}_{m+1,m}y\\
=&amp;\;V_{m+1}(\beta e_1-T^{(1)}_{m+1,m}y).
\end{align*}\]</span> 非常尴尬的是，<span
class="math inline">\(V_{m+1}\)</span> 不是正交矩阵，因此： <span
class="math display">\[\|Ax-b\|_2\leqslant\|V_{m+1}\|_2\|\beta
e_1-T^{(1)}_{m+1,m}y\|_2,\]</span> 这意味着通过求解 <span
class="math inline">\(\displaystyle\min_{y\in \mathbb R^m}\|\beta
e_1-T^{(1)}_{m+1,m}y\|_2\)</span> 得到的结果相较于 GMRES
似乎更粗糙一些。</p>
<hr />
<h1 id="参考书籍">参考书籍</h1>
<ul>
<li><a
target="_blank" rel="noopener" href="https://math.ecnu.edu.cn/~jypan/Teaching/IMP/index.html">优秀的课程</a></li>
</ul>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    

    <footer class="post-footer">

        

    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-ghost"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">XMQ</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
