<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.2.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Serif+Simplified+Chinese:300,300italic,400,400italic,700,700italic%7CMicrosoft+YaHei:300,300italic,400,400italic,700,700italic%7CNoto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"xmq-servicecenter.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="优化问题的大致概念，以及各类优化算法的大致思路。 此处先定义以下要讨论的优化问题的形式： \[\begin{align}\label{problem} \text{最小化}\;f(x),\qquad x\;\text{满足}\;\begin{cases} E_i(x)&#x3D;0:\quad i\in\mathcal E,\\ I_j(x)\geqslant0:\quad j\in\mathcal">
<meta property="og:type" content="article">
<meta property="og:title" content="数值优化">
<meta property="og:url" content="https://xmq-servicecenter.github.io/2024/06/01/Optimization-1/index.html">
<meta property="og:site_name" content="XMQ-维修中心">
<meta property="og:description" content="优化问题的大致概念，以及各类优化算法的大致思路。 此处先定义以下要讨论的优化问题的形式： \[\begin{align}\label{problem} \text{最小化}\;f(x),\qquad x\;\text{满足}\;\begin{cases} E_i(x)&#x3D;0:\quad i\in\mathcal E,\\ I_j(x)\geqslant0:\quad j\in\mathcal">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://xmq-servicecenter.github.io/picture/Wolfe_condition.png">
<meta property="og:image" content="https://xmq-servicecenter.github.io/picture/erciguihua.png">
<meta property="article:published_time" content="2024-05-31T16:00:00.000Z">
<meta property="article:modified_time" content="2024-09-08T09:32:29.491Z">
<meta property="article:author" content="XMQ">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://xmq-servicecenter.github.io/picture/Wolfe_condition.png">


<link rel="canonical" href="https://xmq-servicecenter.github.io/2024/06/01/Optimization-1/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://xmq-servicecenter.github.io/2024/06/01/Optimization-1/","path":"2024/06/01/Optimization-1/","title":"数值优化"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>数值优化 | XMQ-维修中心</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">XMQ-维修中心</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-考前预习"><a href="/%E8%80%83%E5%89%8D%E9%A2%84%E4%B9%A0/" rel="section"><i class="fa fa-th fa-fw"></i>考前预习</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E6%9E%81%E5%B0%8F%E6%9D%A1%E4%BB%B6"><span class="nav-number">1.</span> <span class="nav-text">优化问题的极小条件</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A2%AF%E5%BA%A6%E7%9A%84%E7%9B%B4%E8%A7%82%E5%9B%BE%E5%83%8F"><span class="nav-number">1.1.</span> <span class="nav-text">梯度的直观图像</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E5%B1%80%E9%83%A8%E6%9E%81%E5%B0%8F%E6%9D%A1%E4%BB%B6"><span class="nav-number">1.2.</span> <span class="nav-text">无约束优化问题的局部极小条件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kkt-%E6%9D%A1%E4%BB%B6"><span class="nav-number">1.3.</span> <span class="nav-text">KKT 条件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E4%B8%80%E9%98%B6%E5%BF%85%E8%A6%81%E6%9D%A1%E4%BB%B6"><span class="nav-number">1.4.</span> <span class="nav-text">约束优化问题的一阶必要条件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sfd"><span class="nav-number">1.4.1.</span> <span class="nav-text">SFD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#lfd"><span class="nav-number">1.4.2.</span> <span class="nav-text">LFD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kkt-%E5%AE%9A%E7%90%86"><span class="nav-number">1.4.3.</span> <span class="nav-text">KKT 定理</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%B8%A4%E7%A7%8D%E8%BF%AD%E4%BB%A3%E6%B3%95%E7%9A%84%E6%80%9D%E8%B7%AF"><span class="nav-number">2.</span> <span class="nav-text">两种迭代法的思路</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E7%B2%BE%E7%A1%AE%E7%BA%BF%E6%90%9C%E7%B4%A2%E7%9A%84%E5%88%A4%E5%AE%9A%E6%9D%A1%E4%BB%B6"><span class="nav-number">2.1.</span> <span class="nav-text">非精确线搜索的判定条件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BF%A1%E8%B5%96%E5%9F%9F%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.</span> <span class="nav-text">信赖域方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E8%88%AC%E6%80%9D%E8%B7%AF"><span class="nav-number">2.2.1.</span> <span class="nav-text">一般思路</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%A6%E4%B8%80%E7%A7%8D%E6%80%9D%E8%B7%AFlevenberg-marquardt-%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.2.</span> <span class="nav-text">另一种思路（Levenberg-Marquardt
方法）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">无约束优化问题的拟牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%9B%E9%A1%BF%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="nav-number">3.1.</span> <span class="nav-text">牛顿法的基本思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="nav-number">3.2.</span> <span class="nav-text">拟牛顿法的基本思路</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E7%A7%8D%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BF%AE%E6%AD%A3"><span class="nav-number">3.3.</span> <span class="nav-text">三种常用的修正</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#sr1-%E4%BF%AE%E6%AD%A3"><span class="nav-number">3.3.1.</span> <span class="nav-text">SR1 修正</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bfgs-%E4%B8%8E-dfp-%E4%BF%AE%E6%AD%A3"><span class="nav-number">3.3.2.</span> <span class="nav-text">BFGS 与 DFP 修正</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%97%A0%E7%BA%A6%E6%9D%9F%E4%BC%98%E5%8C%96%E9%97%AE%E9%A2%98%E7%9A%84%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">无约束优化问题的共轭梯度法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E6%AC%A1%E5%87%BD%E6%95%B0%E7%9A%84%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95"><span class="nav-number">4.1.</span> <span class="nav-text">二次函数的共轭梯度法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E8%B7%AF"><span class="nav-number">4.1.1.</span> <span class="nav-text">基本思路</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#p_k-%E7%9A%84%E9%80%89%E5%8F%96"><span class="nav-number">4.1.2.</span> <span class="nav-text">\(p_k\) 的选取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#alpha_k-%E7%9A%84%E9%80%89%E5%8F%96"><span class="nav-number">4.1.3.</span> <span class="nav-text">\(\alpha_k\)
的选取</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E4%BA%8C%E6%AC%A1%E5%87%BD%E6%95%B0%E7%9A%84%E5%85%B1%E8%BD%AD%E6%A2%AF%E5%BA%A6%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">非二次函数的共轭梯度法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98"><span class="nav-number">5.</span> <span class="nav-text">最小二乘问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80%E8%88%AC%E7%9A%84%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98"><span class="nav-number">5.1.</span> <span class="nav-text">一般的最小二乘问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98"><span class="nav-number">5.2.</span> <span class="nav-text">线性最小二乘问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92"><span class="nav-number">6.</span> <span class="nav-text">线性规划</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98%E7%9A%84%E6%A0%87%E5%87%86%E5%BD%A2%E5%BC%8F"><span class="nav-number">6.1.</span> <span class="nav-text">线性规划问题的标准形式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E7%BA%AF%E5%BD%A2%E6%B3%95"><span class="nav-number">6.2.</span> <span class="nav-text">单纯形法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92"><span class="nav-number">7.</span> <span class="nav-text">二次规划</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92%E9%97%AE%E9%A2%98"><span class="nav-number">7.1.</span> <span class="nav-text">二次规划问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8F%AA%E6%9C%89%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%E7%9A%84%E6%83%85%E5%BD%A2"><span class="nav-number">7.2.</span> <span class="nav-text">只有等式约束的情形</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A7%AF%E6%9E%81%E9%9B%86%E6%B3%95"><span class="nav-number">7.3.</span> <span class="nav-text">积极集法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BD%9A%E5%87%BD%E6%95%B0"><span class="nav-number">8.</span> <span class="nav-text">罚函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%96%E7%82%B9%E7%BD%9A%E5%87%BD%E6%95%B0"><span class="nav-number">8.1.</span> <span class="nav-text">外点罚函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A2%9E%E5%B9%BF%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E5%AD%90%E6%B3%95"><span class="nav-number">8.2.</span> <span class="nav-text">增广拉格朗日乘子法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%E6%83%85%E5%BD%A2"><span class="nav-number">8.2.1.</span> <span class="nav-text">等式约束情形</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%AB%E6%9C%89%E4%B8%8D%E7%AD%89%E5%BC%8F%E7%BA%A6%E6%9D%9F%E7%9A%84%E6%83%85%E5%BD%A2"><span class="nav-number">8.2.2.</span> <span class="nav-text">含有不等式约束的情形</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%9C%E7%A2%8D%E7%BD%9A%E5%87%BD%E6%95%B0%E5%86%85%E7%82%B9%E7%BD%9A%E5%87%BD%E6%95%B0"><span class="nav-number">8.3.</span> <span class="nav-text">障碍罚函数（内点罚函数）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%B9%E6%95%B0%E7%BD%9A%E5%87%BD%E6%95%B0%E4%B8%8E%E5%86%85%E7%82%B9%E6%B3%95"><span class="nav-number">8.4.</span> <span class="nav-text">对数罚函数与内点法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%E4%B9%A6%E7%B1%8D"><span class="nav-number">9.</span> <span class="nav-text">参考书籍</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">XMQ</p>
  <div class="site-description" itemprop="description">奇怪的小网站</div>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://xmq-servicecenter.github.io/2024/06/01/Optimization-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="XMQ">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="XMQ-维修中心">
      <meta itemprop="description" content="奇怪的小网站">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="数值优化 | XMQ-维修中心">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          数值优化
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-06-01 00:00:00" itemprop="dateCreated datePublished" datetime="2024-06-01T00:00:00+08:00">2024-06-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-08 17:32:29" itemprop="dateModified" datetime="2024-09-08T17:32:29+08:00">2024-09-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>优化问题的大致概念，以及各类优化算法的大致思路。</p>
<p>此处先定义以下要讨论的优化问题的形式： <blockquote class="colorquote definition" ><p><span class="math display">\[\begin{align}\label{problem}
\text{最小化}\;f(x),\qquad x\;\text{满足}\;\begin{cases}
E_i(x)=0:\quad i\in\mathcal E,\\
I_j(x)\geqslant0:\quad j\in\mathcal I.
\end{cases}
\end{align}\]</span></p>
</blockquote></p>
<hr />
<h1 id="优化问题的极小条件">优化问题的极小条件</h1>
<h2 id="梯度的直观图像">梯度的直观图像</h2>
<p>函数 <span class="math inline">\(f(x)\)</span> 的梯度 <span
class="math inline">\(\nabla f(x)\)</span>
反映了这个函数上升最快的方向，大致的理解思路如下：考虑 <span
class="math inline">\(f(x)\)</span> 在 <span
class="math inline">\(x_0\)</span> 附近的泰勒展开 <span
class="math display">\[f(x_0+\alpha p)\approx f(x_0)+\alpha p^{\mathrm
T}\nabla f(x_0),\]</span> 其中 <span class="math inline">\(p\)</span>
为某个单位矢量，<span class="math inline">\(\alpha&gt;0\)</span> 为在
<span class="math inline">\(p\)</span> 方向的步长。</p>
<p>等号右边第二项为向量内积，所以，当 <span
class="math inline">\(p\)</span> 与 <span class="math inline">\(\nabla
f(x_0)\)</span> 指向相同时 <span class="math inline">\(f(x)\)</span>
上升最显著，<span class="math inline">\(p\)</span> 与 <span
class="math inline">\(\nabla f(x_0)\)</span> 指向相反时 <span
class="math inline">\(f(x)\)</span> 下降最显著。</p>
<h2 id="无约束优化问题的局部极小条件">无约束优化问题的局部极小条件</h2>
<p>一个函数 <span class="math inline">\(f(x)\)</span> 在 <span
class="math inline">\(x^*\)</span>
处取得局部极小值的充分条件与必要条件有：</p>
<blockquote class="colorquote theorem" ><ul>
<li><p>一阶必要条件：如果函数 <span class="math inline">\(f(x)\)</span>
的一阶导是连续的，且 <span class="math inline">\(f(x)\)</span> 在 <span
class="math inline">\(x^*\)</span> 处取得局部极小，那么 <span
class="math inline">\(f(x)\)</span> 在 <span
class="math inline">\(x^*\)</span> 处的一阶导为 0，即 <span
class="math inline">\(\nabla f(x)|_{x=x_0}=0\)</span>。</p></li>
<li><p>二阶必要条件：如果函数 <span class="math inline">\(f(x)\)</span>
的二阶导是连续的，且 <span class="math inline">\(f(x)\)</span> 在 <span
class="math inline">\(x^*\)</span> 处取得局部极小，那么 <span
class="math inline">\(f(x)\)</span> 在 <span
class="math inline">\(x^*\)</span> 处满足一阶导 <span
class="math inline">\(\nabla f(x)|_{x=x^*}=0\)</span> 且二阶导 <span
class="math inline">\(\nabla^2f(x)|_{x=x^*}\)</span> 半正定。</p></li>
<li><p>二阶充分条件：如果函数 <span class="math inline">\(f(x)\)</span>
的二阶导连续，并且在 <span class="math inline">\(x^*\)</span>
处满足一阶导 <span class="math inline">\(\nabla
f(x)|_{x=x^*}=0\)</span>、二阶导 <span
class="math inline">\(\nabla^2f(x)|_{x=x^*}\)</span> 正定，那么 <span
class="math inline">\(x^*\)</span> 是 <span
class="math inline">\(f(x)\)</span> 的一个局部极小值点。</p></li>
</ul>
</blockquote>
<p>这些条件的理解方式很简单： <span
class="math display">\[f(x^\ast+\delta)=f(x^\ast)+\delta^{\mathrm
T}[\nabla f(x^\ast)]+\dfrac12\delta^{\mathrm T}[\nabla^2
f(x^\ast)]\delta+\cdots.\]</span> 然后比较 <span
class="math inline">\(f(x^\ast+\delta)\)</span> 与 <span
class="math inline">\(f(x^\ast)\)</span> 的大小即可：</p>
<ul>
<li><p>一阶必要条件：如果 <span class="math inline">\([\nabla
f(x^\ast)]\)</span> 不为 <span
class="math inline">\(0\)</span>，就必有某个与 <span
class="math inline">\([\nabla f(x^\ast)]\)</span> 呈钝角的 <span
class="math inline">\(\delta\)</span> 使 <span
class="math inline">\(f(x^\ast)\)</span> 下降。</p></li>
<li><p>二阶必要条件：如果 <span class="math inline">\([\nabla
f(x^\ast)]=0\)</span> 但 <span class="math inline">\([\nabla^2
f(x^\ast)]\)</span> 有负的特征值，就可以将 <span
class="math inline">\(\delta\)</span> 取为负特征值的特征向量使 <span
class="math inline">\(f(x^\ast)\)</span> 下降。</p></li>
<li><p>二阶充分条件：如果 <span class="math inline">\([\nabla^2
f(x^\ast)]\)</span> 正定，那么所有非零的 <span
class="math inline">\(\delta\)</span> 都会使得 <span
class="math inline">\(f(x^\ast+\delta)&gt;f(x^\ast)\)</span>。</p></li>
</ul>
<h2 id="kkt-条件">KKT 条件</h2>
<p>对于一般形式的优化问题 (<span
class="math inline">\(\ref{problem}\)</span>)，我们需要引入<strong>拉格朗日函数</strong></p>
<blockquote class="colorquote definition" ><p><span class="math display">\[\mathcal L(x,\lambda):=
f(x)-\sum_{i\in\mathcal E}\lambda_iE_i(x)-\sum_{j\in\mathcal
I}\lambda_jI_j(x).\]</span></p>
</blockquote>
<p>满足以下条件的点 <span class="math inline">\(x\)</span> 称为
<strong>KKT 点</strong>：</p>
<blockquote class="colorquote definition" ><ul>
<li><p><span class="math inline">\(\nabla_x\mathcal
L(x,\lambda)=0.\)</span></p></li>
<li><p>等式约束：<span class="math inline">\(E_i(x)=0\)</span> 或 <span
class="math inline">\(\nabla_{\lambda_i}\mathcal
L(x,\lambda)=0\)</span>，其中 <span class="math inline">\(i\in\mathcal
E.\)</span></p></li>
<li><p>不等式约束：<span class="math inline">\(I_j(x)\geqslant0\)</span>
且 <span class="math inline">\(\lambda_j\geqslant0\)</span> 且 <span
class="math inline">\(\lambda_jI_j(x)=0\)</span>，其中 <span
class="math inline">\(j\in\mathcal I.\)</span></p></li>
</ul>
</blockquote>
<p>在很多情况下，约束优化问题的极值点就是 KKT 点。</p>
<p>KKT 条件中，不等式约束的三个条件可通过如下方式理解：</p>
<ul>
<li><p>如果 <span class="math inline">\(I_j(x)&gt;0\)</span>，那么 <span
class="math inline">\(I_j(x)\geqslant0\)</span>
的条件实际上不起作用，这等价于没有这个约束，也就是 <span
class="math inline">\(\lambda_j=0\)</span>，所以不等式约束的三个条件都能满足。</p></li>
<li><p>如果 <span class="math inline">\(I_j(x)=0\)</span>，那么 <span
class="math inline">\(I_j(x)\geqslant0\)</span>
的条件起了作用，不等式约束的第一个和最后一个条件都能满足。所以问题的关键在于
<span class="math inline">\(\lambda_j\geqslant0\)</span>
的理解方式。</p></li>
</ul>
<p>首先，我们已经知道，梯度 <span class="math inline">\(\nabla
f(x)\)</span> 代表了 <span class="math inline">\(f(x)\)</span>
的上升方向，而 <span class="math inline">\(-\nabla f(x)\)</span>
代表了下降的方向。然后：</p>
<ul>
<li><p>如果 <span class="math inline">\(f(x)\)</span> 的极小值在
<strong>可行区域</strong>（即满足了所有约束条件的区域）的边界上取得，那么
<span class="math inline">\(-\nabla f(x)\)</span>
一定指向可行区域以外，否则其极小值就在可行区域内部取到。</p></li>
<li><p>可行区域由 <span class="math inline">\(I_j(x)\geqslant0\)</span>
确定 (<span class="math inline">\(i\in\mathcal I\)</span>)，因此 <span
class="math inline">\(\nabla I_j(x)\)</span>
一定指向可行区域内部，因为它代表了 <span
class="math inline">\(I_j(x)\)</span> 上升的方向。</p></li>
<li><p>所以 <span class="math inline">\(-\nabla f(x)\)</span> 与 <span
class="math inline">\(\nabla I_j(x)\)</span>
的方向在某种程度上应该是相反的，这就意味着，如果 <span
class="math inline">\(\nabla_x\mathcal L(x,\lambda)=0\)</span> 就必然有
<span class="math inline">\(\lambda_i\geqslant0\)</span>。</p></li>
</ul>
<p>需要注意的是，约束优化问题的极值点不一定是 KKT
点。例如有这样一个例子：</p>
<blockquote class="colorquote example" ><p><span class="math display">\[\begin{align}\label{LFD and SFD, KKT}
\text{最小化}\;f(x,y)=x,\qquad x,y\;\text{满足}
\begin{cases}
x^3-y\geqslant0\\
y\geqslant0
\end{cases}.
\end{align}\]</span></p>
</blockquote>
<p>不难想象，全局极小值点为 <span
class="math inline">\((0,0)\)</span>。这个例子的拉格朗日函数为 <span
class="math inline">\(\mathcal
L(x,y)=x-\lambda_1y-\lambda_2(x^3-y)\)</span>，由 <span
class="math inline">\(\partial\mathcal L/\partial x=0\)</span>
的条件可得 <span
class="math inline">\(1-3\lambda_2x^2=0\)</span>，全局极小值点 <span
class="math inline">\((0,0)\)</span> 不可能满足 KKT 条件。</p>
<h2 id="约束优化问题的一阶必要条件">约束优化问题的一阶必要条件</h2>
<p>要得到约束优化问题的一阶必要条件，需要先引入几个概念和引理：</p>
<blockquote class="colorquote definition" ><ul>
<li><p><strong>可行方向（FD, feasible direction）</strong>：给定 <span
class="math inline">\(x\)</span> 和方向 <span
class="math inline">\(d\)</span>，如果存在一个 <span
class="math inline">\(\delta&gt;0\)</span> 使得 <span
class="math inline">\(x\)</span> 到 <span
class="math inline">\((x+td)\)</span>
的连线上的所有的点都满足约束条件，就说 <span
class="math inline">\(d\)</span> 是 <span
class="math inline">\(x\)</span> 处的可行方向。</p></li>
<li><p><strong>序列可行方向（SFD）</strong>：如果存在序列 <span
class="math inline">\(\{(d_k,\delta_k)\}\)</span> 使得 <span
class="math inline">\(\delta_k&gt;0\)</span>，<span
class="math inline">\(\delta_k\rightarrow0\)</span>，<span
class="math inline">\(d_k\rightarrow d\)</span> 且 <span
class="math inline">\(x_k=x+\delta_kd_k\)</span>
一直满足约束条件，那么就说 <span class="math inline">\(d\)</span> 是
<span class="math inline">\(x\)</span> 的一个序列可行方向。</p></li>
<li><p><strong>线性化可行方向（LFD）</strong>：如果 <span
class="math inline">\(x\)</span> 处的某个方向 <span
class="math inline">\(d\)</span> 满足以下条件就说 <span
class="math inline">\(d\)</span> 是 <span
class="math inline">\(x\)</span> 的一个线性化可行方向： <span
class="math display">\[\begin{align*}
d^{\mathrm T}\nabla E_i(x)=0\;(i\in\mathcal E),\quad d^{\mathrm T}\nabla
I_i(x)\geqslant0\;(i\in\mathcal I),
\end{align*}\]</span></p></li>
</ul>
</blockquote>
<p>可以证明，这几个方向之间的关系为： <blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align*}
\text{FD}(x)\subseteq\text{SFD}(x)\subseteq\text{LFD}(x).
\end{align*}\]</span></p>
</blockquote></p>
<h3 id="sfd">SFD</h3>
<p>形象地来说，一个点处的 SFD
会形成一个“切锥”，它与约束条件的切线有关。例如约束条件 <span
class="math inline">\(x^2+y^2=1\)</span> 在 <span
class="math inline">\((1,0)\)</span> 处的切锥就是直线 <span
class="math inline">\(x=1\)</span> 代表的方向，约束条件 <span
class="math inline">\(-x^2-y^2\geqslant-1\)</span> 在 <span
class="math inline">\((1,0)\)</span> 处的切锥就是半平面 <span
class="math inline">\(x&lt;1\)</span>。</p>
<p>极小值点的一阶必要条件与序列可行化方向 SFD 相关：假设 <span
class="math inline">\(x^\ast\)</span> 是极小值点，然后考虑 <span
class="math display">\[\begin{align*}
\dfrac{f(x^\ast+\delta_k d_k)-f(x^\ast)}{\delta_k}=d_k^{\mathrm
T}[\nabla f(x^\ast)]+O(\delta_k),
\end{align*}\]</span> 两边取 <span
class="math inline">\(k\rightarrow\infty\)</span>
的极限就可得到约束优化问题的一阶必要条件：</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align}\label{SFD-condition}
x^\ast\;\;\text{是}\;\;f(x) \text{ 的局部极小值点
}\quad\Rightarrow\quad\forall d\in \text{SFD 都有 }\;\;d^{\mathrm
T}[\nabla f(x^\ast)]\geqslant0.
\end{align}\]</span></p>
</blockquote>
<h3 id="lfd">LFD</h3>
<p>相较于 SFD，这里的 LFD
因为具有了明确的表达式而更好分析一些。但作为代价，LFD 相比 SFD
包含了一些额外的方向，这些方向可能指向可行区域以外：</p>
<blockquote class="colorquote example" ><ul>
<li>在 (<span class="math inline">\(\ref{LFD and SFD, KKT}\)</span>)
这个例子中，极小值点 <span class="math inline">\((0,0)\)</span> 处的 SFD
就是 <span class="math inline">\(\{(a,0):\;a&gt;0\}\)</span>，而 LFD 为
<span class="math inline">\(\{(a,0):\;a\in\mathbb R\}\)</span>，<span
class="math inline">\(\mathrm{LFD}\backslash\mathrm{SFD}\)</span>
中的方向就指向可行区域以外。</li>
<li>而在约束条件为 <span
class="math inline">\(-x^2-y^2\geqslant-1\)</span> 的例子中，<span
class="math inline">\(\mathrm{SFD}=\mathrm{LFD}\)</span>。</li>
</ul>
</blockquote>
<p>由于 LFD 可能包含指向可行区域以外的方向，所以存在这样的情形：极小值点
<span class="math inline">\(x^\ast\)</span> 点处的 SFD 中没有方向能使
<span class="math inline">\(f(x)\)</span> 下降，但 <span
class="math inline">\(x^\ast\)</span> 点处 LFD 中却有能让 <span
class="math inline">\(f(x)\)</span> 下降的方向，(<span
class="math inline">\(\ref{LFD and SFD, KKT}\)</span>)
就是这样的一个例子。</p>
<h3 id="kkt-定理">KKT 定理</h3>
<p>LFD 与 Farkas 引理相关。我们考虑 <span
class="math inline">\(x\)</span> 点处所有的具有如下形式的方向： <span
class="math display">\[\begin{align*}
S:= \left\lbrace u:\quad u=\sum_{i\in\mathcal E}\lambda_i\nabla
E_i(x)+\sum_{j\in\mathcal I}\lambda_j\nabla I_j(x)\right\rbrace.
\end{align*}\]</span> 不难发现，当 <span
class="math inline">\(x^\ast\)</span>
是我们要考虑的问题的极值点时，<span class="math inline">\(\nabla
f(x^\ast)\in S\)</span>。</p>
<p><span class="math inline">\(S\)</span>
中的方向可以分为两类，其中一类记为 <span
class="math inline">\(S_+\)</span>： <span
class="math display">\[\begin{align*}
S_+=\left\lbrace u=\sum_{i\in\mathcal E}\lambda_i\nabla
E_i(x)+\sum_{j\in\mathcal I}\lambda_j\nabla I_j(x):\quad
\lambda_j\geqslant0\;(\forall j \in \mathcal I)\right\rbrace ,
\end{align*}\]</span> 剩下的归为另一类。不难发现，<span
class="math inline">\(S_+\)</span> 是一个凸集（锥）。</p>
<p>对于 LFD 中的任意一个 <span
class="math inline">\(d\)</span>，不难想象： <span
class="math display">\[\begin{align*}
d^{\mathrm T}u=\sum_{j\in\mathcal I}\lambda_jd^{\mathrm T}\nabla
I_j(x)\geqslant0,\qquad\forall u\in S_+.
\end{align*}\]</span> 这意味着 <span class="math inline">\(S_+\)</span>
分布在以 <span class="math inline">\(d\)</span>
为法向量的超平面的一侧，不会跨过这一超平面，这就是 LFD
中的方向的几何含义。</p>
<p>现在，假设 <span class="math inline">\(\nabla f(x)\in
S\)</span>。</p>
<ul>
<li>如果存在一个 <span class="math inline">\(d\)</span> 让 <span
class="math inline">\(f(x)\)</span> 下降，即 <span
class="math inline">\(d^{\mathrm T}\nabla f&lt;0\)</span>，这就意味着
<span class="math inline">\(\nabla f\)</span> 与 <span
class="math inline">\(S_+\)</span> 分布在以 <span
class="math inline">\(d\)</span> 为法向量的超平面的两侧，也就是 <span
class="math inline">\(\nabla f\notin S_+\)</span>。</li>
<li>反之，如果 <span class="math inline">\(\nabla f\in S\)</span> 但
<span class="math inline">\(\nabla f\notin
S_+\)</span>，那么依据凸集分离定理总能找到一个平面将 <span
class="math inline">\(\nabla f\)</span> 与 <span
class="math inline">\(S_+\)</span> 分隔开，这个平面的指向 <span
class="math inline">\(S_+\)</span> 的法向量 <span
class="math inline">\(d\)</span> 满足 <span
class="math inline">\(d^{\mathrm T}\nabla f&lt;0\)</span>。</li>
</ul>
<p>这样就证明了：如果 <span class="math inline">\(\nabla f(x)\in
S\)</span>，那么 LFD 中存在一个方向 <span
class="math inline">\(d\)</span> 使 <span
class="math inline">\(d^{\mathrm T}\nabla f&lt;0\)</span> 当且仅当 <span
class="math inline">\(\nabla f\notin S_+\)</span>。因此，如果 <span
class="math inline">\(\nabla f\in S\)</span>，就有：</p>
<p><span class="math display">\[\begin{align}
\label{LFD-condition}
\text{对任何}\;\;d\in\text{LFD 都有 }\;\;d^{\mathrm T}[\nabla
f(x^\ast)]\geqslant0\quad\Rightarrow\quad [\nabla f(x^\ast)]\in S_+.
\end{align}\]</span></p>
<p>那么结合 (<span class="math inline">\(\ref{SFD-condition}\)</span>,
<span
class="math inline">\(\ref{LFD-condition}\)</span>)，我们就能得到以下一阶必要条件
(KKT 定理)：</p>
<blockquote class="colorquote theorem" ><p>如果 <span
class="math inline">\(\mathrm{SFD}=\mathrm{LFD}\)</span>，且 <span
class="math inline">\(x^\ast\)</span> 是局部极小值点，那么必然存在一组
<span class="math inline">\(\{\lambda_l\}_{l\in \mathcal E\cup\mathcal
I}\)</span> 使得： <span class="math display">\[\begin{align*}
\nabla f(x^\ast)=\sum_{i\in\mathcal E}\lambda_i\nabla
E_i(x^\ast)+\sum_{j\in\mathcal I}\lambda_j\nabla I_j(x^\ast),\quad
\lambda_j\geqslant0\;(j\in\mathcal I),
\end{align*}\]</span></p>
</blockquote>
<p>所以，问题就归结于 <span
class="math inline">\(\mathrm{SFD}=\mathrm{LFD}\)</span>
何时能够成立。常见的情形有：</p>
<ul>
<li><span class="math inline">\(\{E_i\}_{i\in\mathcal
E}\cup\{I_j\}_{j\in\mathcal I}\)</span> 都是线性函数。</li>
<li>LICQ：<span class="math inline">\(\{\nabla E_i\}_{i\in\mathcal
E}\cup\{\nabla I_j\}_{j\in\mathcal I}\)</span> 线性无关。</li>
<li>Mangasarian-Fromowitz 条件：略(</li>
</ul>
<hr />
<h1 id="两种迭代法的思路">两种迭代法的思路</h1>
<p>求解优化问题的数值方法总是以迭代法为基础，即根据上一个点 <span
class="math inline">\(x_k\)</span> 的信息计算出下一个需要考虑的点 <span
class="math inline">\(x_{k+1}\)</span>，直到某一步的 <span
class="math inline">\(x_k\)</span>
达到收敛条件。迭代法的基本思路有两个：第一个思路是线搜索方法，第二个是信赖域方法。</p>
<p>线搜索方法在得到 <span class="math inline">\(x_k\)</span>
之后，先通过某种方法确定 <span class="math inline">\(x_k\)</span>
处的搜索方向 <span
class="math inline">\(p_k\)</span>，然后在这个方向上通过某种方法确定步长
<span class="math inline">\(\alpha_k\)</span>，就可得到下一个迭代点
<span class="math inline">\(x_{k+1}=x_k+\alpha_k p_k\)</span>。</p>
<p>信赖域方法用某个函数 <span class="math inline">\(m_k(x)\)</span> 近似
<span class="math inline">\(f(x)\)</span>，并假定这一近似在 <span
class="math inline">\(\|x-x_k\|\leqslant\Delta_k\)</span>
——即信赖域——的范围内成立，然后求出 <span
class="math inline">\(m_k(x)\)</span> 在信赖域内的极小值点 <span
class="math inline">\(x_{k+1}\)</span>，以此作为下一个迭代点，并依照结果调整
<span class="math inline">\(\Delta_k\)</span>。</p>
<h2 id="非精确线搜索的判定条件">非精确线搜索的判定条件</h2>
<p>在线搜索方法中，如果明确了搜索方向为 <span
class="math inline">\(p_k\)</span>，就需要选取合适的步长 <span
class="math inline">\(\alpha\)</span>
来确定下一个迭代点。一种可行的方法是精确线搜索，即求出使得 <span
class="math inline">\(f(x_k+\alpha p_k)\)</span> 取最小值的 <span
class="math inline">\(\alpha\)</span> 来作为 <span
class="math inline">\(\alpha_k\)</span>，但这种精确线搜索有时并不划算，因此需要使用非精确线搜索。在非精确线搜索中，只要一个
<span class="math inline">\(\alpha\)</span>
能够满足某些判定条件就可用于确定迭代点。</p>
<p>一个常见的判定条件是 Wolfe 条件，它由 Armijo 条件和曲率条件构成：</p>
<blockquote class="colorquote definition" ><p><strong>Armijo 条件（充分下降条件）</strong>：步长 <span
class="math inline">\(\alpha\)</span> 应该满足 <span
class="math display">\[f(x_k+\alpha p_k)\leqslant f(x_k)+c_1\alpha
p_k^{\mathrm T}\nabla f(x_k):= l(\alpha),\]</span> 其中常数 <span
class="math inline">\(c_1\)</span> 满足 <span
class="math inline">\(0&lt;c_1&lt;1\)</span>。</p>
<p><strong>曲率条件</strong>：步长 <span
class="math inline">\(\alpha\)</span> 应该满足 <span
class="math display">\[p_k^{\mathrm T}\nabla f(x_k+\alpha p_k)\geqslant
c_2p_k^{\mathrm T}\nabla f(x_k),\]</span> 其中常数 <span
class="math inline">\(c_2\)</span> 满足 <span
class="math inline">\(c_1&lt;c_2&lt;1\)</span>。</p>
</blockquote>
<p>这两个条件的含义如下：</p>
<ul>
<li><p>Armijo 条件：步长 <span class="math inline">\(\alpha\)</span>
应该使得 <span class="math inline">\(f(x)\)</span>
充分下降，如下图所示。</p></li>
<li><p>曲率条件的含义如下图所示：不等式左侧为 <span
class="math inline">\(\mathrm d f(x_k+\alpha p_k)/\mathrm
d\alpha\)</span>，不等式右侧为 <span
class="math inline">\(\alpha=0\)</span> 处的 <span
class="math inline">\(\mathrm d f(x_k+\alpha p_k)/\mathrm
d\alpha\)</span>，后者是负的，前者应该比后者更大一些，以便更加接近极小值点。</p></li>
</ul>
<center>
<p><img src="/picture/Wolfe_condition.png" width="75%"></p>
<div
style="display: inline-block; width: 75%; text-align: left; color: #999999; font-size: 8">
<p>Wolfe 条件示意图。 斜率 desired slope 就是 <span
class="math inline">\(f(x_k+\alpha p_k)\)</span> 对 <span
class="math inline">\(\alpha\)</span> 的导数。斜线 <span
class="math inline">\(l(\alpha)\)</span> 是 <span
class="math inline">\(l(\alpha):= f(x_k)+c_1\alpha p_k^{\mathrm T}\nabla
f(x_k)\)</span>。区间 acceptable 就是同时满足这两个条件的 <span
class="math inline">\(\alpha\)</span>：既要让 <span
class="math inline">\(f(x_k+\alpha p_k)\)</span> 位于 <span
class="math inline">\(l(\alpha)\)</span> 下方，又要让 <span
class="math inline">\(f(x_k+\alpha p_k)\)</span> 的斜率相较 <span
class="math inline">\(p_k^{\mathrm T}\nabla f(x_k)\)</span>
更大一些。</p>
</div>
</center>
<p>可以看到，曲率条件也会筛选出那些使得 <span
class="math inline">\(\mathrm d f(x_k+\alpha p_k)/\mathrm
d\alpha&gt;0\)</span> 的 <span
class="math inline">\(\alpha\)</span>。<strong>强 Wolfe 条件</strong>
将曲率条件修改为 <span class="math display">\[\left| p_k^{\mathrm
T}\nabla f(x_k+\alpha p_k)\right| \geqslant\left|  c_2p_k^{\mathrm
T}\nabla f(x_k)\right|,\]</span> 以便将这些 <span
class="math inline">\(\alpha\)</span> 排除出去。</p>
<h2 id="信赖域方法">信赖域方法</h2>
<h3 id="一般思路">一般思路</h3>
<p>信赖域方法就是用一个函数 <span class="math inline">\(m_k\)</span>
来近似第 <span class="math inline">\(k\)</span> 步迭代点 <span
class="math inline">\(x_k\)</span> 附近的 <span
class="math inline">\(f(x)\)</span>，并假设这一近似在 <span
class="math inline">\(\|x-x_k\|&lt;\Delta_k\)</span>
的范围内（即信赖域以内）成立。通常将 <span
class="math inline">\(m_k\)</span> 取为二次函数： <span
class="math display">\[\begin{align}\label{trust-region-problem}
m_k(x)=\dfrac12(x-x_k)^{\mathrm T}G_k(x-x_k)-b_k^{\mathrm
T}(x-x_k)+(\cdots),\quad \|x-x_k\|\leqslant\Delta_k.
\end{align}\]</span></p>
<p>信赖域方法通常会通过某种方式在信赖域内部找出下一个迭代点 <span
class="math inline">\(x_{k+1}\)</span> 使它满足 <span
class="math inline">\(m_k(x_{k+1})&lt;m_k(x_k)\)</span>，并计算 <span
class="math display">\[\begin{align*}
\rho_k:=\dfrac{f(x_k)-f(x_{k+1})}{m_k(x_k)-m_k(x_{k+1})},
\end{align*}\]</span> 然后根据 <span
class="math inline">\(\rho_k\)</span>
的大小确定下一步的要做的两件事情：</p>
<blockquote class="colorquote algorithm" ><ul>
<li><p>调整信赖域大小：</p>
<ul>
<li><p>如果 <span class="math inline">\(\rho_k&lt;1/4\)</span>：这说明
<span class="math inline">\(m_k(x)\)</span> 并不能很好地近似 <span
class="math inline">\(f(x)\)</span>，下一步需要缩小信赖域的范围，例如取
<span
class="math inline">\(\Delta_{k+1}=\Delta_{k}/4\)</span>。</p></li>
<li><p>如果 <span
class="math inline">\(1/4&lt;\rho_k&lt;3/4\)</span>：那么 <span
class="math inline">\(m_k(x)\)</span> 作为 <span
class="math inline">\(f(x)\)</span>
的近似不好不坏，信赖域在下一步迭代时不变：<span
class="math inline">\(\Delta_{k+1}=\Delta_{k}\)</span>。</p></li>
<li><p>如果 <span class="math inline">\(\rho_k&gt;3/4\)</span>：那么
<span class="math inline">\(m_k(x)\)</span> 是 <span
class="math inline">\(f(x)\)</span>
的很好的近似，在下一步迭代时可以适当扩大信赖域的范围，例如取 <span
class="math inline">\(\Delta_{k+1}=2\Delta_{k}\)</span>。</p></li>
</ul></li>
<li><p>选取下一个迭代点：</p>
<ul>
<li><p>如果 <span class="math inline">\(\rho_k&lt;\eta\)</span>（<span
class="math inline">\(\eta\)</span> 为某个位于 <span
class="math inline">\(0\sim1/4\)</span> 间的常数），这一步迭代并没有让
<span class="math inline">\(f(x)\)</span> 发生足够的下降甚至让 <span
class="math inline">\(f(x)\)</span> 发生了上升，因此 <span
class="math inline">\(x_{k+1}\)</span>
不能作为下一个迭代点。此时需要做回退 <span
class="math inline">\(x_{k+1}=x_k\)</span> 并在调整信赖域大小后重新计算
<span class="math inline">\(x_{k+1}\)</span>。</p></li>
<li><p>如果 <span class="math inline">\(\rho_k&gt;\eta\)</span>
那么就可以接受 <span class="math inline">\(x_{k+1}\)</span>
作为新的迭代点。</p></li>
</ul></li>
</ul>
</blockquote>
<p><span id="Levenberg-Marquardt"></p>
<h3
id="另一种思路levenberg-marquardt-方法">另一种思路（Levenberg-Marquardt
方法）</h3>
<p></span></p>
<p>最小化 (<span
class="math inline">\(\ref{trust-region-problem}\)</span>)
可被视为是一个约束优化问题。如果将信赖域取为 <span
class="math inline">\(\|x-x_k\|_2^2\leqslant\Delta_k^2\)</span>，那么这一问题的
KKT 条件为： <span
class="math display">\[\begin{align}\label{LM-method-KKT-condition}
(G_k+\lambda_k I)(x-x_k)=b_k,\quad \lambda_k\geqslant0,\quad
\lambda_k(\|x-x_k\|_2-\Delta_k)=0.
\end{align}\]</span></p>
<p>如果 <span class="math inline">\(G\)</span>
是对称正定的，那么就有一种求解这一约束优化问题的有趣思路。容易看出（通过矩阵对角化），<span
class="math inline">\(\lambda_k\)</span> 越大，求解 (<span
class="math inline">\(\ref{LM-method-KKT-condition}\)</span>)
的第一个式子给出的 <span class="math inline">\(\|x-x_k\|_2\)</span>
就越小，因此，<span class="math inline">\(\lambda_k\)</span>
也可以起到类似于 <span class="math inline">\(\Delta_k\)</span>
的作用。</p>
<p>于是，我们有如下魔改版的信赖域方法：</p>
<blockquote class="colorquote algorithm" ><ul>
<li><p>选定一个 <span class="math inline">\(\lambda_k\)</span>，求解
(<span class="math inline">\(\ref{LM-method-KKT-condition}\)</span>)
的第一个式子得到 <span class="math inline">\(x_{k+1}\)</span>，并计算
<span class="math inline">\(\rho_k\)</span>。</p>
<ul>
<li><p>如果 <span
class="math inline">\(\rho_k&lt;1/4\)</span>：在下一步中选取 <span
class="math inline">\(\lambda_{k+1}=4\lambda_k\)</span>
达到缩小信赖域的效果。</p></li>
<li><p>如果 <span
class="math inline">\(1/4&lt;\rho_k&lt;3/4\)</span>：在下一步中选取
<span class="math inline">\(\lambda_{k+1}=\lambda_k\)</span>。</p></li>
<li><p>如果 <span
class="math inline">\(\rho_k&gt;3/4\)</span>：在下一步中选取 <span
class="math inline">\(\lambda_{k+1}=\lambda_k/2\)</span>
达到扩大信赖域的效果。</p></li>
</ul></li>
<li><p>选取下一个迭代点：同一般思路</p></li>
</ul>
</blockquote>
<hr />
<h1 id="无约束优化问题的拟牛顿法">无约束优化问题的拟牛顿法</h1>
<h2 id="牛顿法的基本思路">牛顿法的基本思路</h2>
<p>牛顿法的基本思路是：对 <span class="math inline">\(\nabla
f(x)\)</span> 做以下近似： <span class="math display">\[\begin{align*}
\nabla f(x)\approx \nabla f(x_k)+[\nabla^2f(x_k)] (x-x_k),
\end{align*}\]</span> 然后通过 <span class="math inline">\(\nabla
f(x_{k+1})=0\)</span> 的条件将下一步的迭代点选为：</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align}\label{Newton-method}
x_{k+1}=x_k-\alpha_k[\nabla^2f(x_k)]^{-1}\nabla f(x_k).
\end{align}\]</span></p>
</blockquote>
<p><span class="math inline">\(\alpha_k=1\)</span> 或由线搜索确定。</p>
<p>搜索方向 <span class="math inline">\(d_k=-[\nabla^2f(x_k)]^{-1}\nabla
f(x_k)\)</span> 通常由求解如下线性方程组确定： <span
class="math display">\[\begin{align*}
[\nabla^2f(x_k)]d=-\nabla f(x_k).
\end{align*}\]</span>
在问题规模较大时，严格求解这一线性方程组往往是很困难的，并且还可能是没有必要的，因此我们可以借用其他方法近似求解这一线性方程组。此外，<span
class="math inline">\([\nabla^2f(x_k)]\)</span>
可能不一定是正定的，这就导致算出的 <span
class="math inline">\(d\)</span>
不一定是下降方向，这也需要采取一些措施处理一下。</p>
<h2 id="拟牛顿法的基本思路">拟牛顿法的基本思路</h2>
<p>牛顿法需要计算二阶导，代价比较大。拟牛顿法的思路就是用一系列比较好算的矩阵
<span class="math inline">\(B_k\)</span> 来近似二阶导 <span
class="math inline">\([\nabla^2f(x_k)]\)</span>，或者用一系列比较好算的矩阵
<span class="math inline">\(H_k\)</span> 来近似二阶导 <span
class="math inline">\([\nabla^2f(x_k)]^{-1}\)</span>。</p>
<p>拟牛顿法在最开始做迭代时，采用 <span
class="math inline">\([\nabla^2f(x_0)]\)</span> 或 <span
class="math inline">\([\nabla^2f(x_0)]^{-1}\)</span> 来作为 <span
class="math inline">\(B_0\)</span> 或 <span
class="math inline">\(H_0\)</span>；在从 <span
class="math inline">\(x_k\)</span> 得到 <span
class="math inline">\(x_{k+1}\)</span> 之后，对 <span
class="math inline">\(B_k\)</span> 或 <span
class="math inline">\(H_k\)</span> 做出修正得到 <span
class="math inline">\(B_{k+1}\)</span> 或 <span
class="math inline">\(H_{k+1}\)</span> 用于下一步的迭代。要让 <span
class="math inline">\(B_k\)</span> 或 <span
class="math inline">\(H_k\)</span> 一直成为 <span
class="math inline">\([\nabla^2f(x_k)]\)</span> 或 <span
class="math inline">\([\nabla^2f(x_k)]^{-1}\)</span>
的好的近似，就需要让它们满足拟牛顿条件。</p>
<p>我们定义： <span class="math display">\[\begin{align*}
y_k:= \nabla f(x_{k+1})-\nabla f(x_k),\quad s_k:= x_{k+1} - x_k.
\end{align*}\]</span> 显然，二阶导数近似地满足： <span
class="math display">\[\begin{align*}
\nabla f(x_k)\approx \nabla f(x_{k+1})+[\nabla^2f(x_{k+1})]
(x_k-x_{k+1}),\quad \text{或}\quad [\nabla^2f(x_{k+1})]s_k=y_k.
\end{align*}\]</span> 拟牛顿条件就是：</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align}\label{secant condition}
B_{k+1}s_k=y_k,\quad \text{或}\quad s_k=H_{k+1}y_k.
\end{align}\]</span></p>
</blockquote>
<h2 id="三种常用的修正">三种常用的修正</h2>
<h3 id="sr1-修正">SR1 修正</h3>
<p>最简单的对 <span class="math inline">\(B_k\)</span> 或 <span
class="math inline">\(H_k\)</span> 做出修正得到 <span
class="math inline">\(B_{k+1}\)</span> 或 <span
class="math inline">\(H_{k+1}\)</span> 的方法是 SR1（对称秩
1）修正。其思路如下：假设 <span class="math display">\[\begin{align*}
B_{k+1}=B_k+u_ku_k^{\mathrm T}.
\end{align*}\]</span> <span class="math inline">\(B_{k+1}\)</span> 与
<span class="math inline">\(B_k\)</span> 只相差一个秩为 <span
class="math inline">\(1\)</span>
的对称矩阵，这就是这一方法的名称的来源。于是由拟牛顿条件 (<span
class="math inline">\(\ref{secant condition}\)</span>) 可以得到： <span
class="math display">\[\begin{align*}
u_k(u_k^{\mathrm T}s_k)+B_ks_k=y_k.
\end{align*}\]</span> 注意到 <span class="math inline">\((u_k^{\mathrm
T}s_k)\)</span> 是常数，所以 <span class="math inline">\(u_k\)</span>
的形式必然为 <span
class="math inline">\(u_k=a(y_k-B_ks_k)\)</span>。代入以上表达式就不难算出
<span class="math inline">\(a^2=1/[(y_k-B_ks_k)^{\mathrm
T}s_k]\)</span>，这样就得到了 <span
class="math inline">\(B_{k+1}\)</span>。<span
class="math inline">\(H_{k+1}\)</span> 可通过一样的方法得到。</p>
<p>SR1 修正的最终表达式为：</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align*}
\begin{split}
\text{SR1}:\quad
B_{k+1}^{\text{SR1}}=&amp;\;B_k+\dfrac{1}{(y_k-B_ks_k)^{\mathrm
T}s_k}(y_k-B_ks_k)(y_k-B_ks_k)^{\mathrm T},\\
\text{SR1}:\quad
H_{k+1}^{\text{SR1}}=&amp;\;H_k+\dfrac{1}{(s_k-H_ky_k)^{\mathrm
T}y_k}(s_k-H_ky_k)(s_k-H_ky_k)^{\mathrm T}.
\end{split}
\end{align*}\]</span></p>
</blockquote>
<p>可以证明，这两种修正实际上是等价的。</p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>线性代数告诉我们： <span class="math display">\[(A + XRY )^{-1}=
A^{-1}-A^{-1}X(R^{-1}+ Y A^{-1}X)^{-1}Y A^{-1}\]</span></p>
<p>于是：</p>
<p><span class="math display">\[\begin{align*}
(B_{k+1}^{\text{SR1}})^{-1} &amp;= B_k^{-1}-B_k^{-1}(y_k-B_ks_k)
[(y_k-B_ks_k)^{\mathrm T}s_k+(y_k-B_ks_k)^{\mathrm
T}B_k^{-1}(y_k-B_ks_k)] (y_k-B_ks_k)^{\mathrm T}B_k^{-1}\\
&amp;=B_k^{-1}-(B_k^{-1}y_k-s_k) [(y_k-B_ks_k)^{\mathrm T}B_k^{-1}y_k]
(B_k^{-1}y_k-s_k)^{\mathrm T}\\
&amp;=B_k^{-1}-(B_k^{-1}y_k-s_k) [(B_k^{-1}y_k-s_k)^{\mathrm T}y_k]
(B_k^{-1}y_k-s_k)^{\mathrm T}.
\end{align*}\]</span></p>
<p>这与 <span class="math inline">\(H_{k+1}^{\text{SR1}}\)</span>
一致。</p>

    </div>
</div>
<p>SR1 方法的问题在于，并不能保证 <span
class="math inline">\(B_{k+1}\)</span> 或 <span
class="math inline">\(H_{k+1}\)</span> 的正定性。</p>
<h3 id="bfgs-与-dfp-修正">BFGS 与 DFP 修正</h3>
<p>另两套重要的修正方法是 BFGS 与 DFP 修正。BFGS 方法的思路如下：假设
<span class="math display">\[\begin{align*}
B_{k+1}=B_k+u_ku_k^{\mathrm T}+v_kv_k^{\mathrm T}.
\end{align*}\]</span> 由拟牛顿条件可得： <span
class="math display">\[\begin{align*}
y_k=B_ks_k+u_k(u_k^{\mathrm T}s_k)+v_k(v_k^{\mathrm T}s_k).
\end{align*}\]</span> 假设 <span
class="math inline">\(u_k=aB_ks_k\)</span>、<span
class="math inline">\(v_k=b y_k\)</span>，不难算出 <span
class="math inline">\(a^2=-1/[(B_ks_k)^{\mathrm T}s_k]\)</span>、<span
class="math inline">\(b^2=1/(y_k^{\mathrm T}s_k)\)</span>，这样就得到了
BFGS 修正。</p>
<p>DFP 修正就是对 <span class="math inline">\(H_k\)</span>
做同样的流程，最终的结果是：</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align*}
\begin{split}
\text{BFGS}:\quad&amp;B_{k+1}^{\text{BFGS}}=B_k-\dfrac{1}{(B_ks_k)^{\mathrm
T}s_k}(B_ks_k)(B_ks_k)^{\mathrm T}+\dfrac{1}{y_k^{\mathrm
T}s_k}y_ky_k^{\mathrm T},\\
\text{DFP}:\quad&amp;H_{k+1}^{\text{DFP}}=H_k-\dfrac{1}{(H_ky_k)^{\mathrm
T}y_k}(H_ky_k)(H_ky_k)^{\mathrm T}+\dfrac{1}{s_k^{\mathrm
T}y_k}s_ks_k^{\mathrm T}.
\end{split}
\end{align*}\]</span></p>
</blockquote>
<p>此外还可以证明：</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align*}
\begin{split}
\text{BFGS}:\quad&amp;H_{k+1}^{\text{BFGS}}=H_k+\left(1+\dfrac{y_k^{\mathrm
T} H_ky_k}{y_k^{\mathrm T} s_k}\right)\dfrac{s_ks_k^{\mathrm
T}}{s_k^{\mathrm T}y_k}-\dfrac{s_ky_k^{\mathrm T} H_k+H_ky_ks_k^{\mathrm
T}}{y_k^{\mathrm T}s_k},\\
\text{DFP}:\quad&amp;B_{k+1}^{\text{DFP}}=B_k+\left(1+\dfrac{s_k^{\mathrm
T} B_ks_k}{s_k^{\mathrm T} y_k}\right)\dfrac{y_ky_k^{\mathrm
T}}{y_k^{\mathrm T}s_k}-\dfrac{y_ks_k^{\mathrm T} B_k+B_ks_ky_k^{\mathrm
T}}{s_k^{\mathrm T}y_k}.
\end{split}
\end{align*}\]</span></p>
</blockquote>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>仅证明 BFGS 情形。</p>
<p>线性代数告诉我们： <span class="math display">\[(A + XRY )^{-1}=
A^{-1}-A^{-1}X(R^{-1}+ Y A^{-1}X)^{-1}Y A^{-1}\]</span></p>
<p>我们先将 <span class="math inline">\(A,X,R,Y\)</span> 取为： <span
class="math display">\[\begin{align*}
A&amp;=B_k+\dfrac{1}{y_k^{\mathrm T}s_k}y_ky_k^{\mathrm T},\\
X&amp;=B_ks_k,\quad Y=(B_ks_k)^{\mathrm T},\\
R&amp;=\dfrac{-1}{(B_ks_k)^{\mathrm T}s_k}.
\end{align*}\]</span></p>
<p>于是： <span class="math display">\[\begin{align*}
H_{k+1} &amp;= A^{-1}-A^{-1}X(R^{-1}+ Y A^{-1}X)^{-1}Y A^{-1}\\
&amp;=A^{-1}-A^{-1}(B_ks_k) [-(B_ks_k)^{\mathrm T}s_k+ (B_ks_k)^{\mathrm
T} A^{-1}(B_ks_k)]^{-1} (B_ks_k)^{\mathrm T} A^{-1}\\
&amp;=A^{-1}-A^{-1}(B_ks_k) [-(B_ks_k)^{\mathrm T}s_k+ (B_ks_k)^{\mathrm
T}A^{-1}A A^{-1}(B_ks_k)]^{-1} (B_ks_k)^{\mathrm T} A^{-1}.
\end{align*}\]</span> 然后再用以上公式计算 <span
class="math inline">\(A^{-1}\)</span>： <span
class="math display">\[A^{-1}=H_k-\dfrac{H_ky_ky_k^{\mathrm T}
H_k}{y_k^{\mathrm T}s_k+ y_k^{\mathrm T} H_ky_k}.\]</span> 由于 <span
class="math inline">\(B_kH_k=H_kB_k=I\)</span>，并且 <span
class="math inline">\(B_k,H_k\)</span> 都是对称矩阵，所以： <span
class="math display">\[\begin{align*}
(B_ks_k)^{\mathrm T}A^{-1}(B_ks_k)
&amp;=(B_ks_k)^{\mathrm T}s_k-\dfrac{(s_k^{\mathrm T}y_k)(y_k^{\mathrm
T} s_k)}{y_k^{\mathrm T}s_k+ y_k^{\mathrm T} H_ky_k}.
\end{align*}\]</span> 这样一来： <span
class="math display">\[\begin{align*}
H_{k+1}&amp;=A^{-1}-A^{-1}(B_ks_k) [-(B_ks_k)^{\mathrm T}s_k+
(B_ks_k)^{\mathrm T} A^{-1}(B_ks_k)]^{-1} (B_ks_k)^{\mathrm T} A^{-1}\\
&amp;=H_k-\dfrac{H_ky_ky_k^{\mathrm T} H_k}{y_k^{\mathrm T}s_k+
y_k^{\mathrm T} H_ky_k}+\dfrac{y_k^{\mathrm T}s_k+ y_k^{\mathrm T}
H_ky_k}{(s_k^{\mathrm T}y_k)(y_k^{\mathrm T}
s_k)}A^{-1}(B_ks_k)(B_ks_k)^{\mathrm T} A^{-1}.
\end{align*}\]</span> 然后： <span class="math display">\[\begin{align*}
A^{-1}(B_ks_k)&amp;=s_k-\dfrac{H_ky_k(y_k^{\mathrm T} s_k)}{y_k^{\mathrm
T}s_k+ y_k^{\mathrm T} H_ky_k},\\
(B_ks_k)^{\mathrm T} A^{-1}&amp;=s_k^{\mathrm T}-\dfrac{(s_k^{\mathrm
T}y_k)y_k^{\mathrm T} H_k}{y_k^{\mathrm T}s_k+ y_k^{\mathrm T} H_ky_k}.
\end{align*}\]</span> 以及： <span class="math display">\[\begin{align*}
A^{-1}(B_ks_k)(B_ks_k)^{\mathrm T}
A^{-1}&amp;=\left[s_k-\dfrac{H_ky_k(y_k^{\mathrm T} s_k)}{y_k^{\mathrm
T}s_k+ y_k^{\mathrm T} H_ky_k}\right]\left[s_k^{\mathrm
T}-\dfrac{(s_k^{\mathrm T}y_k)y_k^{\mathrm T} H_k}{y_k^{\mathrm T}s_k+
y_k^{\mathrm T} H_ky_k}\right]\\
&amp;=s_ks_k^{\mathrm T}-\dfrac{(s_k^{\mathrm T}y_k)s_ky_k^{\mathrm T}
H_k}{y_k^{\mathrm T}s_k+ y_k^{\mathrm T}
H_ky_k}-\dfrac{H_ky_ks_k^{\mathrm T}(y_k^{\mathrm T} s_k)}{y_k^{\mathrm
T}s_k+ y_k^{\mathrm T} H_ky_k}+\dfrac{H_ky_k(y_k^{\mathrm T}
s_k)(s_k^{\mathrm T}y_k)y_k^{\mathrm T} H_k}{(y_k^{\mathrm T}s_k+
y_k^{\mathrm T} H_ky_k)^2}\\
&amp;=s_ks_k^{\mathrm T}-\dfrac{(s_k^{\mathrm T}y_k)}{y_k^{\mathrm
T}s_k+ y_k^{\mathrm T} H_ky_k}(s_ky_k^{\mathrm T} H_k+H_ky_ks_k^{\mathrm
T})+\dfrac{(y_k^{\mathrm T} s_k)(s_k^{\mathrm T}y_k)}{(y_k^{\mathrm
T}s_k+ y_k^{\mathrm T} H_ky_k)^2}H_ky_ky_k^{\mathrm T} H_k
\end{align*}\]</span> 这样一来就能算出： <span
class="math display">\[\begin{align*}
H_{k+1}&amp;=H_k-\dfrac{H_ky_ky_k^{\mathrm T} H_k}{y_k^{\mathrm T}s_k+
y_k^{\mathrm T} H_ky_k}+\dfrac{y_k^{\mathrm T}s_k+ y_k^{\mathrm T}
H_ky_k}{(s_k^{\mathrm T}y_k)(y_k^{\mathrm T}
s_k)}A^{-1}(B_ks_k)(B_ks_k)^{\mathrm T} A^{-1}\\
&amp;=H_k-\dfrac{H_ky_ky_k^{\mathrm T} H_k}{y_k^{\mathrm T}s_k+
y_k^{\mathrm T} H_ky_k}+\dfrac{y_k^{\mathrm T}s_k+ y_k^{\mathrm T}
H_ky_k}{(s_k^{\mathrm T}y_k)(y_k^{\mathrm T} s_k)}s_ks_k^{\mathrm
T}-\dfrac{s_ky_k^{\mathrm T} H_k+H_ky_ks_k^{\mathrm T}}{y_k^{\mathrm
T}s_k}+\dfrac{H_ky_ky_k^{\mathrm T} H_k}{y_k^{\mathrm T}s_k+
y_k^{\mathrm T} H_ky_k}\\
&amp;=H_k+\dfrac{y_k^{\mathrm T}s_k+ y_k^{\mathrm T}
H_ky_k}{(s_k^{\mathrm T}y_k)(y_k^{\mathrm T} s_k)}s_ks_k^{\mathrm
T}-\dfrac{s_ky_k^{\mathrm T} H_k+H_ky_ks_k^{\mathrm T}}{y_k^{\mathrm
T}s_k}\\
&amp;=H_k+\left(1+\dfrac{y_k^{\mathrm T} H_ky_k}{y_k^{\mathrm T}
s_k}\right)\dfrac{s_ks_k^{\mathrm T}}{s_k^{\mathrm
T}y_k}-\dfrac{s_ky_k^{\mathrm T} H_k+H_ky_ks_k^{\mathrm T}}{y_k^{\mathrm
T}s_k}.
\end{align*}\]</span></p>

    </div>
</div>
<p>在 BFGS 公式中，<span class="math inline">\(H_{k+1}\)</span>
还可写为： <span
class="math display">\[H_{k+1}^{\text{BFGS}}=\left(I-\dfrac{s_ky_k^{\mathrm
T}}{y_k^{\mathrm T}s_k}\right)H_k\left(I-\dfrac{y_ks_k^{\mathrm
T}}{s_k^{\mathrm T}y_k}\right)+\dfrac{s_ks_k^{\mathrm T}}{s_k^{\mathrm
T}y_k}.\]</span> 基于这一递推公式，人们发明了针对高维问题的有限内存 BFGS
（L-BFGS）方法。这一方法在计算 <span
class="math inline">\(H_{k+1}\)</span> 时记录下 <span
class="math inline">\(s_{(k-m)\sim k}\)</span> 与 <span
class="math inline">\(y_{(k-m)\sim k}\)</span>，并通过某种方式假设一个
<span
class="math inline">\(H_{k-m}\)</span>——通常是某种对角矩阵——然后利用
<span class="math inline">\((m+1)\)</span>
次以上递推公式就能得到计算所需的 <span
class="math inline">\(H_{k+1}\)</span>。由于实际计算时需要存储的都是向量（对角矩阵也是向量）而非矩阵，因此计算占用的内存可以大大减少。<span
class="math inline">\(m\)</span> 的取值通常为 <span
class="math inline">\(3\sim8\)</span>。</p>
<hr />
<h1 id="无约束优化问题的共轭梯度法">无约束优化问题的共轭梯度法</h1>
<h2 id="二次函数的共轭梯度法">二次函数的共轭梯度法</h2>
<p>现在，考虑二次函数的无约束优化问题： <span
class="math display">\[\begin{align}\label{quadratic-problem}
f(x)=\dfrac12 x^{\mathrm T}Gx-b^{\mathrm T}x,
\end{align}\]</span> 其中 <span class="math inline">\(G\)</span>
为对称正定矩阵。</p>
<h3 id="基本思路">基本思路</h3>
<p>我们可以指定 <span class="math inline">\(n\)</span>
个线性无关的方向（<span class="math inline">\(n\)</span> 为 <span
class="math inline">\(x\)</span> 的维数）<span
class="math inline">\(p_{1\sim n}\)</span>，使其满足： <span
class="math display">\[\begin{align*}
p^{\mathrm T}_iGp_j=\delta_{ij}(p^{\mathrm T}_iGp_i),
\end{align*}\]</span> 很容易看出来，<span
class="math inline">\(p_i\)</span> 线性无关，且构成了 <span
class="math inline">\(\mathbb R^n\)</span> 的一组 <span
class="math inline">\(G\)</span>-正交基——如果将矢量内积 <span
class="math inline">\(\langle x,y\rangle\)</span> 定义为 <span
class="math inline">\(x^{\mathrm T}Gy\)</span> 的话。</p>
<p>由于 <span class="math inline">\(p_i\)</span> 是一组基，所以最小化
(<span class="math inline">\(\ref{quadratic-problem}\)</span>)
时选取的初值 <span class="math inline">\(x_0\)</span> 与严格最小值 <span
class="math inline">\(x^\ast\)</span> 之间的差异一定可以用 <span
class="math inline">\(p_i\)</span> 线性表示出来： <span
class="math display">\[\begin{align*}
x_0=x^\ast-\sum_{i=0}^{n-1} \alpha_ip_i.
\end{align*}\]</span> 共轭梯度法生成如下序列： <span
class="math display">\[\begin{align}\label{CG x_k}
x_k=x^\ast-\sum_{i=k}^{n-1} \alpha_ip_i=x_{k-1}+\alpha_{k-1}p_{k-1},
\end{align}\]</span> 使得 <span class="math inline">\(n\)</span>
步迭代后的 <span class="math inline">\(x_{n}\)</span> 就等于 <span
class="math inline">\(x^\ast\)</span>。也就是说，共轭梯度法在第 <span
class="math inline">\(k\)</span> 步迭代的时候会消除 <span
class="math inline">\(x_0\)</span> 与 <span
class="math inline">\(x^\ast\)</span> 在 <span
class="math inline">\(p_k\)</span> 方向上的差异，遍历完全部的 <span
class="math inline">\(n\)</span> 个方向之后，<span
class="math inline">\(x_n\)</span> 自然就会等于 <span
class="math inline">\(x^\ast\)</span>。</p>
<p>共轭梯度法并不是在一开始就确定了全部的 <span
class="math inline">\(p_k\)</span>，<span
class="math inline">\(p_k\)</span> 的具体形式需要在计算出 <span
class="math inline">\(x_{0\sim k}\)</span>，<span
class="math inline">\(p_{0\sim (k-1)}\)</span> 以及 <span
class="math inline">\(r_{0\sim k}\)</span> 之后才能确定（因为 <span
class="math inline">\(p_k\)</span> 是用于从 <span
class="math inline">\(x_k\)</span> 得到 <span
class="math inline">\(x_{k+1}\)</span> 的），其中 <span
class="math inline">\(r_k\)</span> 表示 <span
class="math inline">\(x_k\)</span> 处的梯度： <span
class="math display">\[\begin{align*}
r_k:= Gx_k-b.
\end{align*}\]</span></p>
<h3 id="p_k-的选取"><span class="math inline">\(p_k\)</span> 的选取</h3>
<p>以下我们就来讨论 <span class="math inline">\(p_k\)</span>
的选取方式。如果 <span class="math inline">\(r_k\)</span> 在某一步变为
<span class="math inline">\(0\)</span>
就意味着我们已经找到了原二次函数的极值点。如果不为 <span
class="math inline">\(0\)</span>，那么，由 (<span
class="math inline">\(\ref{CG x_k}\)</span>) 以及 <span
class="math inline">\(Gx^\ast=b\)</span> 可以发现 <span
class="math display">\[\begin{align}\label{CG-r_k}
r_k=\left(Gx^\ast-\sum_{i=k}^{n-1}
\alpha_iGp_i\right)-b=-\sum_{i=k}^{n-1} \alpha_iGp_i.
\end{align}\]</span></p>
<p>由于 <span class="math inline">\(p_i\)</span> 应该是 <span
class="math inline">\(G\)</span>-正交的，所以 <span
class="math inline">\(p_{0\sim(k-1)}^{\mathrm T}r_k=0\)</span>，这意味着
<span class="math inline">\(r_k\)</span> 中必定包含了独立于 <span
class="math inline">\(p_0\sim p_{k-1}\)</span>
以外的方向，于是我们可以从 <span class="math inline">\(r_k\)</span>
中提取出一个方向作为 <span class="math inline">\(p_k\)</span>。</p>
<p>我们假定 <span class="math inline">\(p_k\)</span> 具有如下形式：
<span class="math display">\[\begin{align}\label{p_k-form}
p_k=-r_k+\beta_kp_{k-1}+\sum_{j=0}^{k-2}\gamma_{k,j}p_j.
\end{align}\]</span> 系数 <span
class="math inline">\(\beta_k,\gamma_{k,j}\)</span> 应当使 <span
class="math inline">\(p^{\mathrm
T}_{0\sim(k-1)}Gp_k=0\)</span>。可以证明， 符合这一条件的系数为： <span
class="math display">\[\gamma_{k,j}=0,\]</span> 以及</p>
<blockquote class="colorquote theorem" ><p><span class="math display">\[\begin{align}\label{CG-beta_k}
\beta_k=\dfrac{r_k^{\mathrm T}(r_k-r_{k-1})\quad \text{或}\quad
r_k^{\mathrm T}r_k}{p_{k-1}^{\mathrm T}(r_k-r_{k-1})\quad \text{或}\quad
(-p_{k-1}^{\mathrm T}r_{k-1})\quad\text{或}\quad r_{k-1}^{\mathrm
T}r_{k-1}},
\end{align}\]</span></p>
</blockquote>
<p>此外，这样定出的 <span class="math inline">\(p_k\)</span> 满足：
<span class="math display">\[p_{i=0\sim(k-1)}^{\mathrm T}r_k=0,\quad
r_{i=0\sim(k-1)}^{\mathrm T}r_k=0.\]</span></p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>首先证明 <span class="math inline">\(\gamma_{k,j}\)</span> 全部为
<span class="math inline">\(0\)</span>。</p>
<p>为此，我们在 (<span class="math inline">\(\ref{p_k-form}\)</span>)
式两侧同时左乘 <span class="math inline">\(p_j^{\mathrm T}G\)</span>：
<span class="math display">\[\begin{align*}
(p_j^{\mathrm T}Gp_j)\gamma_{k,j}=&amp;\;p_j^{\mathrm
T}Gp_k+p_j^{\mathrm T}Gr_k-\beta p_j^{\mathrm T}Gp_{k-1}=p_j^{\mathrm
T}Gr_k\\
=&amp;\;\dfrac{1}{\alpha_j}(x_{j+1}-x_j)^{\mathrm T}Gr_k\\
=&amp;\;\dfrac{1}{\alpha_j}(r_{j+1}-r_j)^{\mathrm T}r_k.
\end{align*}\]</span> 其中 <span
class="math inline">\(j=0\sim(k-2)\)</span>。不难看出，只需证明 <span
class="math inline">\(r_{i=0\sim(k-1)}^{\mathrm T}r_k=0\)</span>
就能完成证明。</p>
<p>(<span class="math inline">\(\ref{CG-r_k}\)</span>) 告诉我们 <span
class="math inline">\(r_k\)</span> 是 <span
class="math inline">\(Gp_{k\sim(n-1)}\)</span> 的线性组合，因此如果
<span class="math inline">\(i&lt;k\)</span> 就一定有： <span
class="math display">\[p_{i=0\sim(k-1)}^{\mathrm T}r_k=0.\]</span></p>
<p>从我们选取的 (<span class="math inline">\(\ref{p_k-form}\)</span>)
可以看出，<span class="math inline">\(r_i\)</span> 是 <span
class="math inline">\(p_{0\sim i}\)</span> 的线性组合，因此： <span
class="math display">\[r_{i=0\sim(k-1)}^{\mathrm T}r_k=0.\]</span>
这样就完成了证明。</p>
<hr />
<p>由于 <span class="math inline">\(\gamma_{k,j}\)</span> 全部为 <span
class="math inline">\(0\)</span>，所以 <span
class="math inline">\(p_k\)</span> 的形式为： <span
class="math display">\[\begin{align*}
p_k=-r_k+\beta_kp_{k-1}.
\end{align*}\]</span> 再结合 <span
class="math inline">\(p_{k-1}^{\mathrm T}Gp_k=0\)</span> 的条件可以算出
<span class="math inline">\(\beta_k\)</span>： <span
class="math display">\[\begin{align*}
\beta_k=\dfrac{p^{\mathrm T}_{k-1}Gr_k}{p_{k-1}^{\mathrm
T}Gp_{k-1}}=\dfrac{r_k^{\mathrm T}Gp_{k-1}}{p_{k-1}^{\mathrm
T}Gp_{k-1}}.
\end{align*}\]</span> 从 (<span
class="math inline">\(\ref{CG-r_k}\)</span>) 可以看出 <span
class="math inline">\(r_k=r_{k-1}+\alpha_{k-1}Gp_{k-1}\)</span>，所以
<span
class="math inline">\(Gp_{k-1}\propto(r_k-r_{k-1})\)</span>，因此以上表达式也可以写为：
<span class="math display">\[\begin{align*}
\beta_k=\dfrac{r_k^{\mathrm T}(r_k-r_{k-1})}{p_{k-1}^{\mathrm
T}(r_k-r_{k-1})}=\dfrac{r_k^{\mathrm T}(r_k-r_{k-1})\quad \text{或}\quad
r_k^{\mathrm T}r_k}{p_{k-1}^{\mathrm T}(r_k-r_{k-1})\quad \text{或}\quad
(-p_{k-1}^{\mathrm T}r_{k-1})\quad\text{或}\quad r_{k-1}^{\mathrm
T}r_{k-1}},
\end{align*}\]</span> 第二个等号用到了 <span
class="math inline">\(r_k^{\mathrm T}r_{0\sim(k-1)}=0\)</span>、<span
class="math inline">\(p_{0\sim(k-1)}^{\mathrm T}r_k=0\)</span>
等各类结果。这一结果的重要之处在于：<span
class="math inline">\(\beta_k\)</span> 的表达式中可以摆脱二阶导 <span
class="math inline">\(G\)</span>。</p>

    </div>
</div>
<h3 id="alpha_k-的选取"><span class="math inline">\(\alpha_k\)</span>
的选取</h3>
<p>在明确了 <span class="math inline">\(\beta_k\)</span>
之后，我们可以考虑 <span class="math inline">\(f(x_k+\alpha
p_k)\)</span>： <span class="math display">\[\begin{align*}
f(x_k+\alpha p_k)=\dfrac12p_k^{\mathrm T}Gp_k\alpha^2+p_k^{\mathrm
T}(Gx_k-b)\alpha+(\cdots),
\end{align*}\]</span> <span class="math inline">\(\alpha_k\)</span>
应该让 <span class="math inline">\(f(x_k+\alpha p_k)\)</span>
取极小值以便消除 <span class="math inline">\(x_k\)</span> 与 <span
class="math inline">\(x^\ast\)</span> 在 <span
class="math inline">\(p_k\)</span> 方向上的差距： <span
class="math display">\[\begin{align}\label{CG alpha_k}
\alpha_k=-\dfrac{p_k^{\mathrm T}r_k}{p_k^{\mathrm T}Gp_k}.
\end{align}\]</span></p>
<p>总结一下，二次函数的共轭梯度法的流程大致为： <span
class="math display">\[x_k\rightarrow r_k\rightarrow p_k\rightarrow
\alpha_k\rightarrow x_{k+1}(=x_k+\alpha_kp_k).\]</span></p>
<h2 id="非二次函数的共轭梯度法">非二次函数的共轭梯度法</h2>
<p>非二次函数的共轭梯度法直接使用 (<span
class="math inline">\(\ref{p_k-form}\)</span>, <span
class="math inline">\(\ref{CG-beta_k}\)</span>) 算出 <span
class="math inline">\(p_k\)</span> 作为搜索方向（<span
class="math inline">\(\gamma_{k,j}=0\)</span>，<span
class="math inline">\(r_k\)</span> 就直接取为 <span
class="math inline">\(x_k\)</span> 的导数），然后在 <span
class="math inline">\(p_k\)</span>
方向做线搜索进而得到下一个迭代点。</p>
<hr />
<h1 id="最小二乘问题">最小二乘问题</h1>
<h2 id="一般的最小二乘问题">一般的最小二乘问题</h2>
<p>最小二乘问题的被优化函数 <span class="math inline">\(f(x)\)</span>
一般具有如下形式： <span class="math display">\[\begin{align*}
f(x)=\dfrac12\sum_{i=1}^m [r_i(x)]^2,\quad m&gt;n\;(n\text{ 为
}\;x\text{ 的维数}).
\end{align*}\]</span> 我们可以将 <span class="math inline">\(r_{i=1\sim
m}\)</span> 排成列向量，我们还可以定义一个 <span
class="math inline">\(m\)</span> 行 <span
class="math inline">\(n\)</span> 列的矩阵 <span
class="math inline">\(J\)</span>，使其第 <span
class="math inline">\(i\)</span> 行就是排成行向量的 <span
class="math inline">\(\nabla r_i(x)\)</span>： <span
class="math display">\[\begin{align*}
r(x):=[r_1,r_2,\cdots,r_m]^{\mathrm T},\quad J(x):=[\nabla r_1,\nabla
r_2,\cdots,\nabla r_m]^{\mathrm T}.
\end{align*}\]</span> 不难看出，<span
class="math inline">\(f(x)\)</span> 的一阶导和二阶导分别为： <span
class="math display">\[\begin{align*}
\nabla f(x) = J(x)^{\mathrm T}r(x),\quad \nabla^2f(x)=J(x)^{\mathrm
T}J(x)+\sum_{i=1}^mr_i(x)\nabla^2r_i(x).
\end{align*}\]</span></p>
<p>线性最小二乘问题可以用牛顿法处理。在牛顿法的流程中，如果近似地认为
<span class="math display">\[\begin{align*}
\nabla^2f(x)\approx J^{\mathrm T}(x)J(x),
\end{align*}\]</span> 也就是忽略 <span class="math inline">\(\nabla
f(x)\)</span> 中的第二项，就得到了高斯-牛顿法。这一方法非常适用于 <span
class="math inline">\(r_i(x)\)</span>
都比较小或都比较接近线性函数的情形。</p>
<p>另一种重要的方法是 Levenberg-Marquardt 方法，其基本思路就是 <a
href="#Levenberg-Marquardt">Levenberg-Marquardt 方法小节</a>
所描述的思路。事实上，Levenberg-Marquardt
方法可被视为是信赖域方法的起源之一。稍加改进的 Levenberg-Marquardt
方法是现在处理无约束最小二乘问题的最优方法。</p>
<h2 id="线性最小二乘问题">线性最小二乘问题</h2>
<p>最简单的最小二乘问题就是线性最小二乘问题，这里的被优化函数的形式是：
<span class="math display">\[\begin{align*}
f(x)=\dfrac12(Jx-y)^{\mathrm T}(Jx-y).
\end{align*}\]</span></p>
<p>我们可以用 QR 分解的思路处理线性最小二乘问题。假设 <span
class="math inline">\(J\)</span> 的 QR 分解为： <span
class="math display">\[\begin{align*}
J=Q_{m\times m}\begin{bmatrix}R_{n\times n}\\0_{(m-n)\times
n}\end{bmatrix}=\begin{bmatrix}(Q_1)_{m\times n}&amp;(Q_2)_{m\times
(m-n)}\end{bmatrix}\begin{bmatrix}R_{n\times n}\\0_{(m-n)\times
n}\end{bmatrix}
\end{align*}\]</span> 于是： <span class="math display">\[\begin{align*}
f(x)=\dfrac12(Q^{\mathrm T}Jx-Q^{\mathrm T}y)^{\mathrm T}(Q^{\mathrm
T}Jx-Q^{\mathrm T}y)=\dfrac12\|Rx-Q_1^{\mathrm
T}y\|^2+\dfrac12\|Q_2^{\mathrm T}y\|^2.
\end{align*}\]</span>
这意味着，线性最小二乘问题的解就是如下线性方程组的解： <span
class="math display">\[\begin{align*}
Rx=Q_1^{\mathrm T}y.
\end{align*}\]</span></p>
<p>我们也可以在以上方程组两边同时乘以 <span
class="math inline">\(R^{\mathrm T}\)</span>。注意到 <span
class="math inline">\(R^{\mathrm T}R=J^{\mathrm T}J\)</span>，<span
class="math inline">\(R^{\mathrm T}Q_1^{\mathrm T}=(Q_1R)^{\mathrm
T}=J^{\mathrm T}\)</span>，所以以上方程组也就等价于： <span
class="math display">\[\begin{align*}
J^{\mathrm T}Jx=J^{\mathrm T}y.
\end{align*}\]</span> <span class="math inline">\(J^{\mathrm
T}J\)</span> 总是对称半正定的，所以可通过 Cholesky
分解等方法求解这一线性方程组。</p>
<p>另一种思路是对 <span class="math inline">\(J\)</span> 做 SVD
分解，再参考 QR 分解的思路。</p>
<hr />
<h1 id="线性规划">线性规划</h1>
<h2 id="线性规划问题的标准形式">线性规划问题的标准形式</h2>
<p>优化目标与约束条件都是 <span class="math inline">\(x\)</span>
的线性函数的优化问题就是线性规划问题。线性规划问题的标准形式为； <span
class="math display">\[\begin{align}
\text{最小化}\;\;c^{\mathrm T}x,\qquad x\;\text{满足}\;
\begin{cases}
x\geqslant0\\
Ax=b
\end{cases}.
\end{align}\]</span> 其中 <span class="math inline">\(A\)</span> 为
<span class="math inline">\(m\times n\)</span> 的行满秩矩阵。</p>
<p>对于形如 <span class="math inline">\(a&#39;^{\mathrm T}x\geqslant
b&#39;\)</span> 这样的不等式约束，我们可以引入松弛变量 <span
class="math inline">\(x&#39;\geqslant0\)</span> 来使其变为 <span
class="math inline">\(a^{\mathrm T}x-x&#39;=b\)</span>。对于取值范围为
<span class="math inline">\(\mathbb R\)</span> 的自变量 <span
class="math inline">\(x&#39;&#39;\)</span>，我们可以引入两个变量 <span
class="math inline">\(x_1\geqslant0\)</span> 和 <span
class="math inline">\(x_2\geqslant0\)</span>，将 <span
class="math inline">\(x&#39;&#39;\)</span> 改写为 <span
class="math inline">\(x_1-x_2\)</span>。如果是最大化 <span
class="math inline">\(c^{\mathrm T}x\)</span>，那么可将优化目标选取为
<span class="math inline">\(-c^{\mathrm
T}x\)</span>。这样一来，所有线性规划问题都能被化为以上标准形式。</p>
<h2 id="单纯形法">单纯形法</h2>
<p>处理线性规划问题的最重要的算法是单纯形法。需要注意的是，除了线性规划的单纯性法以外，优化问题中还有另一种截然不同的、不需要计算导数的单纯形法。</p>
<p>在高中时我们都学习过二维线性规划，线性规划的结果总是能够在可行区域的顶点上取得。这一点在更一般的线性规划问题中也是成立的。线性规划的单纯形法的迭代步骤就是在这些“顶点”之间左右横跳，最终找到结果。</p>
<p>由于线性规划问题的约束具有 <span class="math inline">\(Ax=b\)</span>
的形式，并且 <span class="math inline">\(A\)</span>
是行满秩的，所以一个很自然的想法就是从中挑出 <span
class="math inline">\(x\)</span> 的 <span
class="math inline">\(m\)</span> 个分量（称为基变量），并记为 <span
class="math inline">\(x_B\)</span>，然后将剩下的部分部分记为 <span
class="math inline">\(x_N\)</span>。我们当然可以调整 <span
class="math inline">\(x\)</span> 中各个分量的顺序（同时也调整 <span
class="math inline">\(A\)</span> 与 <span
class="math inline">\(c\)</span>），使得基变量排在前面： <span
class="math display">\[\begin{align*}
x=[x_B,\;x_N]^{\mathrm T},\quad A=[A_B,\;A_N],\quad c =
[c_B,\;c_N]^{\mathrm T}.
\end{align*}\]</span> 由于 <span class="math inline">\(A\)</span>
是行满秩的，所以 <span class="math display">\[\begin{align}\label{xB xN}
Ax=b\quad\Leftrightarrow\quad A_Bx_B+A_Nx_N=b\quad\Leftrightarrow\quad
x_B=A_B^{-1}b-A_B^{-1}A_Nx_N.
\end{align}\]</span> 将它代入优化目标： <span
class="math display">\[\begin{align*}
c^{\mathrm T}x=c_B^{\mathrm T}x_B+c_N^{\mathrm T}x_N=c_B^{\mathrm
T}A_B^{-1}b+(c_N^{\mathrm T}-c_B^{\mathrm T}A_B^{-1}A_N)x_N.
\end{align*}\]</span></p>
<p>如果 <span class="math inline">\((c_N^{\mathrm T}-c_B^{\mathrm
T}A_B^{-1}A_N)\)</span> 的分量全是正数，由于 <span
class="math inline">\(x_N\geqslant0\)</span>，那么 <span
class="math inline">\(c^{\mathrm T}x\)</span> 的极小值就在 <span
class="math inline">\(x_N=0\)</span>
处取得。实际上可以证明，满足约束条件的区域的“顶点”一定是那些有 <span
class="math inline">\((n-m)\)</span> 个分量为 <span
class="math inline">\(0\)</span> 的点，即 <span
class="math inline">\(x_N=0\)</span> 的点。</p>
<p>如果 <span class="math inline">\((c_N^{\mathrm T}-c_B^{\mathrm
T}A_B^{-1}A_N)\)</span> 的第 <span class="math inline">\(i\)</span>
个分量是负数，就意味着我们可以增加 <span
class="math inline">\((x_N)_i\)</span> 来使 <span
class="math inline">\(c^{\mathrm T}x\)</span> 减小。很多情况下 <span
class="math inline">\((x_N)_i\)</span> 并不是无限制的，因为 <span
class="math inline">\(x_N\)</span> 会通过 (<span
class="math inline">\(\ref{xB xN}\)</span>) 影响 <span
class="math inline">\(x_B\)</span>。如果当 <span
class="math inline">\((x_N)_i\)</span> 增大到使某个 <span
class="math inline">\((x_B)_j\)</span> 变为 <span
class="math inline">\(0\)</span> 的程度，那么就应该调整 <span
class="math inline">\(B\)</span> 与 <span
class="math inline">\(N\)</span>，将 <span
class="math inline">\((x_B)_j\)</span> 加入 <span
class="math inline">\(x_N\)</span>，将 <span
class="math inline">\((x_N)_i\)</span> 加入 <span
class="math inline">\(x_B\)</span>。如果这种增加是无限制的，就说明目前的线性规划问题无解。</p>
<p>以上就是单纯形法的基本思路，当然还有很多细节没有补充，例如怎样选取
<span class="math inline">\((x_N)_i\)</span>
才不会导致死循环，如何选择初值等等。</p>
<hr />
<h1 id="二次规划">二次规划</h1>
<h2 id="二次规划问题">二次规划问题</h2>
<p>二次规划就是在线性约束下求解一个二次函数的极小值。二次规划问题的标准形式为：
<span class="math display">\[\text{最小化}\;f(x)=g^{\mathrm
T}x+\dfrac12x^{\mathrm T}Hx,\qquad x\;\text{满足}\;\begin{cases}
a_i^{\mathrm T}x=b_i:\quad i\in\mathcal E,\\
a_j^{\mathrm T}x\geqslant b_j:\quad j\in\mathcal I.
\end{cases}\]</span></p>
<p>二次规划问题的拉格朗日函数为： <span class="math display">\[\mathcal
L(x,\lambda):= \dfrac12x^{\mathrm T}Hx+g^{\mathrm T}x-\sum_{i\in\mathcal
E}\lambda_i(a_i^{\mathrm T}x-b_i)-\sum_{j\in\mathcal
I}\lambda_j(a_j^{\mathrm T}x-b_j).\]</span></p>
<p>相应的 KKT 点 <span
class="math inline">\((x^\ast,\lambda^\ast)\)</span> 满足：</p>
<p><span class="math display">\[\begin{align*}
\begin{cases}
&amp;Hx^\ast+g=\sum_i\lambda_i^\ast a_i+\sum_j\lambda_j^\ast a_j,\\[2mm]
&amp;\lambda_j^\ast(a_j^{\mathrm T}x^\ast-b_j)=0 :\quad j\in\mathcal
I,\\[2.5mm]
&amp;\lambda_j^\ast\geqslant0:\quad j\in\mathcal I.
\end{cases}
\end{align*}\]</span></p>
<p>求解二次规划问题的算法可应用到求解一般约束优化问题的序列二次规划法（sequential
quadratic programming，SQP）中。SQP
的基本思路就是在迭代的每一步中用一个二次函数去近似优化目标函数（对目标函数做二阶泰勒展开），同时将约束全部转化为线性约束（对约束函数做一阶泰勒展开），进而将非线性的约束优化问题转化为二次规划问题。</p>
<h2 id="只有等式约束的情形">只有等式约束的情形</h2>
<p>求解二次规划的经典算法是积极集法，这一方法会将二次规划问题转化为一个只有等式约束的二次规划问题，因此这里首先讨论如何求解只有等式约束的情形。</p>
<p>只有等式约束时，KKT 条件等价于：</p>
<p><span class="math display">\[\begin{align*}\begin{bmatrix}H&amp;-A\\
A^{\mathrm T}&amp;0\end{bmatrix}
\begin{bmatrix}x^\ast \\ \lambda^\ast\end{bmatrix}
=\begin{bmatrix}-g\\ b\end{bmatrix}\quad\text{或}\quad
\begin{bmatrix}G&amp;-A\\-A^{\mathrm T}&amp;0\end{bmatrix}
\begin{bmatrix}x^\ast \\ \lambda^\ast
\end{bmatrix}=-\begin{bmatrix}g\\ b\end{bmatrix}.
\end{align*}\]</span> 其中 <span
class="math inline">\(A=[a_1,a_2,\cdots]\)</span> 以及 <span
class="math inline">\(b=[b_1,b_2,\cdots]^{\mathrm
T}\)</span>。求解这一线性方程组就能得到等式约束二次规划的解。有一些算法可以专门用于处理这种形式的矩阵。</p>
<p>处理等式约束二次规划的另一种思路是广义消去法。假设 <span
class="math inline">\(\{z_i\}_{i=1}^{n-m}\)</span> 都满足 <span
class="math inline">\(A^{\mathrm T}z_i=0\)</span> 且线性无关，即 <span
class="math inline">\(\{z_i\}_{i=1}^{n-m}\)</span> 构成了 <span
class="math inline">\(A^{\mathrm T}\)</span>
的零空间的一组基。我们定义： <span class="math display">\[
Z=[z_1,z_2,\cdots,z_{n-m}].
\]</span> 我们还可以找出一个 <span class="math inline">\(n\times
m\)</span> 矩阵 <span class="math inline">\(Y\)</span> 使得 <span
class="math inline">\([Y,Z]\)</span> 是满秩的，即 <span
class="math inline">\(Y\)</span> 的列向量 <span
class="math inline">\(A\)</span> 的像空间的一组基。这样一来，任何向量
<span class="math inline">\(x\)</span> 都可写为： <span
class="math display">\[
x = Yx_Y+Zx_Z.
\]</span> 从 <span class="math inline">\(A^{\mathrm T}x=b\)</span>
不难解出 <span class="math inline">\(x_Y=(A^{\mathrm
T}Y)^{-1}b\)</span>，于是： <span class="math display">\[f(x)=g^{\mathrm
T}x+\dfrac12x^{\mathrm T}Hx=\dfrac12x_Z^{\mathrm T}(Z^{\mathrm
T}HZ)x_Z+\left[HY(A^{\mathrm T}Y)^{-1}b+g\right]^{\mathrm
T}Zx_Z+(\text{常数})\]</span> 显然，以上函数的极小值点为： <span
class="math display">\[x_Z^\ast = -(Z^{\mathrm T}HZ)^{-1}Z^{\mathrm
T}\left[HY(A^{\mathrm T}Y)^{-1}b+g\right].\]</span>
所以以上二次规划问题的解就是： <span
class="math display">\[\begin{align*}
x^\ast&amp;=Y(A^{\mathrm T}Y)^{-1}b-Z(Z^{\mathrm T}HZ)^{-1}Z^{\mathrm
T}\left[HY(A^{\mathrm T}Y)^{-1}b+g\right].
\end{align*}\]</span> 拉格朗日乘子可通过 <span
class="math inline">\(Hx^\ast-A\lambda^\ast=-g\)</span> 的条件算出。</p>
<h2 id="积极集法">积极集法</h2>
<p>如下图所示。在二次规划中，如果 <span class="math inline">\(H\)</span>
是正定的，那么 <span class="math inline">\(f(x)\)</span>
的等值线就是一系列的椭圆，此时 <span class="math inline">\(f(x)\)</span>
的极值点一定是在可行区域的边界上取到。</p>
<center>
<p><img src="/picture/erciguihua.png" width="75%"></p>
<div
style="display: inline-block; width: 75%; text-align: left; color: #999999; font-size: 8">
<p>二次规划问题的等值线与可行区域示意图。图片来源：<a
href="#https://blog.csdn.net/hxudhdjuf/article/details/112374967">这里</a>。</p>
</div>
</center>
<p>此时，在二次规划的最优点上，不等式约束要么不起作用，要么起作用进而变成等式约束。积极集法的思路就是去找到这些起作用的不等式约束。</p>
<p>对于二次规划问题，如果一个不等式约束不起作用，那么它的拉格朗日乘子就是
0；如果一个不等式约束起作用了，那么它的拉格朗日乘子就必然不为负数。基于这一点，人们提出了与线性规划的单纯形法非常相似的积极集法。</p>
<p>假设在第 <span class="math inline">\(k\)</span>
步，我们找到了二次规划的一个可行点 <span
class="math inline">\(x_k\)</span>，在 <span
class="math inline">\(x_k\)</span> 上起作用的约束的下标集合为 <span
class="math inline">\(\mathcal S_k\subset\mathcal E\cup\mathcal
I\)</span>。积极集法首先求解以下等式二次规划问题： <span
class="math display">\[\begin{align*}
&amp;\text{最小化}\quad f_k(d):=g^{\mathrm
T}(x_k+d)+\dfrac12(x_k+d)^{\mathrm T}H(x_k+d),\\
&amp;d\;\text{满足}\;a_l^{\mathrm T}d=0:\quad l\in S_k.
\end{align*}\]</span> 然后：</p>
<blockquote class="colorquote algorithm" ><ul>
<li>如果 <span class="math inline">\(d\neq 0\)</span>，那么从 <span
class="math inline">\(x_k\)</span> 出发沿着 <span
class="math inline">\(d\)</span>
前进，直到碰到可行区域的边界，将这个边界上的点作为下一步的迭代点 <span
class="math inline">\(x_{k+1}\)</span>，并将边界对应的约束加入 <span
class="math inline">\(S_k\)</span> 得到 <span
class="math inline">\(S_{k+1}\)</span>。</li>
<li>如果 <span
class="math inline">\(d=0\)</span>，则判断以上等式二次规划问题的拉格朗日乘子。
<ul>
<li>如果所有乘子都非负，就意味着找到了一个 KKT 点，算法可以结束。</li>
<li>如果有乘子为负数，那么找出最小的那个乘子，将相应的约束从 <span
class="math inline">\(S_k\)</span>
中删除，然后重新求解以上等式二次规划问题。</li>
</ul></li>
</ul>
<p>这就是积极集法的思路。不难看出，这一思路还可被用于其他线性约束问题中。</p>
</blockquote>
<hr />
<h1 id="罚函数">罚函数</h1>
<p>对于优化问题 (<span
class="math inline">\(\ref{problem}\)</span>)，我们定义如下记号： <span
class="math display">\[\bar c_k(x)=\begin{cases}
E_k(x):\quad&amp; k\in\mathcal E,\\
\min\{0,I_k(x)\}:\quad&amp; k\in\mathcal I,
\end{cases}\]</span> 用来描述 <span class="math inline">\(x\)</span>
点处对约束的违背情况：<span class="math inline">\(x\)</span> 满足第
<span class="math inline">\(k\)</span> 个约束时 <span
class="math inline">\(c_k(x)=0\)</span>，否则 <span
class="math inline">\(c_k(x)\neq0\)</span>。</p>
<h2 id="外点罚函数">外点罚函数</h2>
<p>外点罚函数方法的基本思路是将优化目标从 <span
class="math inline">\(f(x)\)</span> 修改为 <span
class="math display">\[P(x,\sigma):=f(x)+\sigma\cdot p[\bar
c(x)],\]</span> 其中新加入的惩罚项 <span class="math inline">\(\sigma
p[\bar c(x)]\)</span> 在 <span class="math inline">\(\bar c(x)\)</span>
全部为 <span class="math inline">\(0\)</span> 时为 <span
class="math inline">\(0\)</span>，并且是每一个 <span
class="math inline">\(\bar c_k(x)\)</span> 的增函数，参数 <span
class="math inline">\(\sigma\)</span>
称为罚因子。由于这类罚函数的惩罚项是针对可行区域以外的点的，所以这类罚函数被称为外点罚函数。</p>
<p>不难想象，只要 <span class="math inline">\(\sigma\)</span>
足够大，可行区域内即 <span class="math inline">\(\bar c(x)\)</span> 全为
<span class="math inline">\(0\)</span>
的点由于具有更小的惩罚项而更容易给出较小的 <span
class="math inline">\(P(x)\)</span>，这样就能达到施加约束条件的目的。但是特别大的
<span class="math inline">\(\sigma\)</span>
往往会造成数值上的困难，因此，人们会采用逐步增加 <span
class="math inline">\(\sigma\)</span> 的方法：</p>
<blockquote class="colorquote algorithm" ><ul>
<li>给定 <span class="math inline">\(\sigma_k\)</span> 以及初值 <span
class="math inline">\(x_{k-1}\)</span>，用无约束优化算法求出 <span
class="math inline">\(P(x,\sigma_k)\)</span> 的极小值点 <span
class="math inline">\(x_{k}\)</span>。</li>
<li>按某种规则选取一个比 <span class="math inline">\(\sigma_k\)</span>
更大的 <span
class="math inline">\(\sigma_{k+1}\)</span>，回到上一步。</li>
</ul>
</blockquote>
<p>可以证明，只要原问题有可行点，即存在一个点使得 <span
class="math inline">\(\bar c(x)\)</span> 全部为 <span
class="math inline">\(0\)</span>，并且 <span
class="math inline">\(k\rightarrow\infty\)</span> 时 <span
class="math inline">\(\sigma_k\rightarrow\infty\)</span>，以上算法产生的序列
<span class="math inline">\(x_k\)</span> 就会收敛到原问题的最优解 <span
class="math inline">\(x^\ast\)</span> 上。并且在收敛过程中，序列 <span
class="math inline">\(f(x_k)\)</span> 随 <span
class="math inline">\(k\)</span> 的增加而逐渐增加。</p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>我们用 <span class="math inline">\(x(\sigma)\)</span> 表示 <span
class="math inline">\(P(x,\sigma)\)</span> 的最小值点。因此以上算法中
<span class="math inline">\(x_k=x(\sigma_k)\)</span></p>
<hr />
<p>首先我们证明 <span class="math inline">\(x(\sigma)\)</span>
是以下问题的最优解： <span
class="math display">\[\text{最小化}\;f(x),\quad x\;\text{满足}\;p[\bar
c(x)]\leqslant p[\bar c(x(\sigma))]\]</span> 这是因为：任取一个满足
<span class="math inline">\(p[\bar c(x)]\leqslant p[\bar
c(x(\sigma))]\)</span> 的 <span class="math inline">\(x\)</span> 都有：
<span class="math display">\[P(x,\sigma)=f(x)+\sigma p[\bar
c(x)]\geqslant f(x(\sigma))+\sigma p[\bar c(x(\sigma))],\]</span> 因此
<span class="math display">\[f(x)\geqslant
f(x(\sigma))+\sigma\Big[p[\bar c(x(\sigma))]-p[\bar c(x)]\Big]\geqslant
f(x(\sigma)).\]</span></p>
<hr />
<p>只要能够证明 <span
class="math inline">\(\sigma_k\rightarrow+\infty\)</span> 时 <span
class="math inline">\(p[\bar c(x_k)]\rightarrow 0\)</span>
就能证明以上算法产生的 <span class="math inline">\(x_k\)</span>
能够收敛到原问题的最优解上。以下证明这一点。</p>
<p>假设原问题有一个可行点 <span class="math inline">\(\hat
x\)</span>，即 <span class="math inline">\(p[\bar c(\hat
x)]=0\)</span>，那么依据 <span class="math inline">\(x_k\)</span>
的定义，有： <span class="math display">\[f(\hat x)+\sigma_k p[\bar
c(\hat x)]\geqslant f(x_k)+\sigma_kp[\bar c(x_k)],\]</span> 这意味着：
<span class="math display">\[p[\bar
c(x(\sigma_k))]\leqslant\dfrac{f(\hat x)-f(x_k)}{\sigma_k}\]</span></p>
<p>由于 <span class="math inline">\(k\rightarrow+\infty\)</span> 时
<span class="math inline">\(\sigma_k\rightarrow+\infty\)</span>，只要
<span class="math inline">\(k\)</span> 越大时 <span
class="math inline">\(f(x_k)\)</span> 越大——即 <span
class="math inline">\(f(\hat x)-f(x_k)\)</span>
是一个单调下降的序列（并且它不可能小于 0 因为 <span
class="math inline">\(p[\bar c(x)]\)</span>
总是非负的）——那么不等号右侧的序列就会趋于 <span
class="math inline">\(0\)</span>，这样就能完成证明。</p>
<hr />
<p>现在证明 <span class="math inline">\(k\)</span> 越大时 <span
class="math inline">\(f(x_k)\)</span> 越大。只需证明 <span
class="math inline">\(\sigma_2&gt;\sigma_1\)</span> 时 <span
class="math inline">\(f(x_2)&gt;f(x_1)\)</span> 即可。根据 <span
class="math inline">\(x_k\)</span> 的定义，有：</p>
<p><span class="math display">\[\begin{align*}
f(x_1)+\sigma_1p[\bar c(x_1)]&amp;\leqslant f(x_2)+\sigma_1p[\bar
c(x_2)],\\
f(x_2)+\sigma_2p[\bar c(x_2)]&amp;\leqslant f(x_1)+\sigma_2p[\bar
c(x_1)],\\
\end{align*}\]</span></p>
<p>也就是： <span class="math display">\[\begin{align*}
f(x_1)-\sigma_1p[\bar c(x_2)]&amp;\leqslant f(x_2)-\sigma_1p[\bar
c(x_1)],\\
f(x_2)+\sigma_2p[\bar c(x_2)]&amp;\leqslant f(x_1)+\sigma_2p[\bar
c(x_1)],\\
\end{align*}\]</span></p>
<p>因此 <span class="math inline">\((\sigma_2-\sigma_1)p[\bar
c(x_2)]\leqslant(\sigma_2-\sigma_1)p[\bar c(x_1)]\)</span>，也就是：
<span class="math display">\[p[\bar c(x_2)]\leqslant p[\bar
c(x_1)].\]</span></p>
<p>然后就有： <span class="math display">\[f(x_2)\geqslant
f(x_1)+\sigma_1p[\bar c(x_1)]-\sigma_1p[\bar c(x_2)]\geqslant
f(x_1).\]</span></p>
<hr />
<p>以上证明过程实际上告诉我们：<span class="math inline">\(x_k\)</span>
最终会趋于原问题的最优解 <span
class="math inline">\(x^\ast\)</span>，但趋近的方向实际上是 <span
class="math inline">\(f(x_k)\)</span> 逐渐上升的方向。这意味着 <span
class="math inline">\(x_k\)</span> 是从可行区域外部逐步接近 <span
class="math inline">\(x^\ast\)</span> 的。</p>

    </div>
</div>
<p>最早的罚函数是二次罚函数（Courant 罚函数），其形式为： <span
class="math display">\[P(x,\sigma)=f(x)+\sigma\left[\sum_{i\in\mathcal
E}[\bar c_i(x)]^2+\sum_{j\in\mathcal I}[\bar
c_j(x)]^2\right].\]</span></p>
<p>以上算法产生的序列 <span class="math inline">\(x_k\)</span> 是 <span
class="math inline">\(P(x,\sigma_k)\)</span> 的极值点，所以 <span
class="math inline">\(P(x,\sigma_k)\)</span> 对 <span
class="math inline">\(x_k\)</span> 的一阶导必然为 <span
class="math inline">\(0\)</span>，即： <span
class="math display">\[\nabla f(x_k)+\sum_{l\in\mathcal E\cup\mathcal
I}2\sigma_k\bar c_l(x_k)\nabla \bar c_l(x_k)=0.\]</span> 考虑到 <span
class="math inline">\(x_k\)</span> 终将趋于原问题的最优解，因此序列
<span class="math display">\[\lambda_{l,k}:=-2\sigma_k\bar
c_l(x_k)\]</span> 在 <span
class="math inline">\(k\rightarrow\infty\)</span>
时将趋于原问题的拉格朗日乘子 <span
class="math inline">\(\lambda_l^\ast\)</span>。</p>
<p>重要的外点罚函数除了二次罚函数以外，还有 <span
class="math inline">\(l_1\)</span>-罚函数： <span
class="math display">\[P(x,\sigma)=f(x)+\sigma\sum_{l\in\mathcal
E\cup\mathcal I}\left|\bar c_l(x)\right|.\]</span>
这一罚函数是不可微的。但可以证明，与二次罚函数不同的是，只要 <span
class="math inline">\(\sigma\)</span> 大于某个有限值（不需要将 <span
class="math inline">\(\sigma\)</span> 趋于无穷大），原问题的极小值点就是
<span
class="math inline">\(l_1\)</span>-罚函数的极小值点，满足这一性质的罚函数称为精确罚函数。</p>
<h2 id="增广拉格朗日乘子法">增广拉格朗日乘子法</h2>
<h3 id="等式约束情形">等式约束情形</h3>
<p>对于只有等式约束的情形，增广拉格朗日乘子法考虑如下形式的罚函数（增广拉格朗日函数）：
<span class="math display">\[L(x,\lambda,\sigma)=f(x)-\sum_{i\in\mathcal
E}\lambda_iE_i(x)+\sigma\sum_{i\in\mathcal E}[E_i(x)]^2,\]</span>
然后和普通的罚函数方法一样不断地调节 <span
class="math inline">\(\lambda\)</span> 与 <span
class="math inline">\(\sigma\)</span> 以便获得最优解。对于 <span
class="math inline">\(\sigma\)</span>，可以像外点罚函数一样逐步将它增大，例如取
<span class="math inline">\(\sigma_{k+1}=10\sigma_k\)</span>；对于 <span
class="math inline">\(\lambda_{i,k}\)</span>，则可参照以下思路：</p>
<p>假设 <span class="math inline">\((x^\ast,\lambda^\ast)\)</span>
是原问题的最优解与拉格朗日乘子，并且还假定 <span
class="math inline">\(x^\ast\)</span> 是 <span
class="math inline">\(P(x,\lambda_k,\sigma_k)\)</span> 的最优解，所以：
<span class="math display">\[\begin{align*}
&amp;\nabla f(x^\ast)-\sum_{i\in\mathcal E}\lambda_i^\ast \nabla
E_i(x^\ast)=0,\\
&amp;\nabla f(x^\ast)-\sum_{i\in\mathcal E}\left[\lambda_{k,i}
-2\sigma_k E_i(x^\ast) \right]\nabla E_i(x^\ast)=0.
\end{align*}\]</span> 这意味着： <span
class="math display">\[\lambda_i^\ast=\lambda_{k,i} -2\sigma_k
E_i(x^\ast).\]</span> 尽管我们并不能得到 <span
class="math inline">\(x^\ast\)</span>，但我们可以得到对 <span
class="math inline">\(x^\ast\)</span> 的估计 <span
class="math inline">\(x_k\)</span>，这给我们提供了如下更新思路：<span
class="math inline">\(\lambda_{k+1,i}=\lambda_{k,i} -2\sigma_k
E_i(x_k)\)</span>。</p>
<p>至此，我们得到了等式约束的增广拉格朗日乘子法：</p>
<blockquote class="colorquote algorithm" ><ul>
<li>给定 <span class="math inline">\(\sigma_k\)</span>，<span
class="math inline">\(\lambda_k\)</span> 以及初值 <span
class="math inline">\(x_{k-1}\)</span>，用无约束优化算法求出增广拉格朗日函数
<span class="math inline">\(L(x,\lambda_k, \sigma_k)\)</span> 的极小值点
<span class="math inline">\(x_{k}\)</span>。</li>
<li>选取 <span class="math inline">\(\lambda_{k+1} = \lambda_k-2\sigma_k
E(x_k)\)</span>。</li>
<li>按某种规则选取一个比 <span class="math inline">\(\sigma_k\)</span>
更大的 <span
class="math inline">\(\sigma_{k+1}\)</span>，回到第一步。</li>
</ul>
</blockquote>
<p>可以证明，与外点罚函数不同，如果严格的拉格朗日乘子 <span
class="math inline">\(\lambda^\ast\)</span>
已知，增广拉格朗日乘子法只需要让 <span
class="math inline">\(\sigma_k\)</span> 足够大但不需要趋于 <span
class="math inline">\(+\infty\)</span> 就能让 <span
class="math inline">\(L(x,\lambda^\ast,\sigma_k)\)</span> 的最优解 <span
class="math inline">\(x_k\)</span> 成为原问题的最优解；只要 <span
class="math inline">\(\lambda\)</span> 足够接近 <span
class="math inline">\(\lambda^\ast\)</span>，<span
class="math inline">\(L(x,\lambda,\sigma_k)\)</span> 的最优解 <span
class="math inline">\(x_k\)</span> 也会非常接近原问题的最优解。</p>
<h3 id="含有不等式约束的情形">含有不等式约束的情形</h3>
<p>对于不等式约束，可以考虑引入一些松弛变量将其转化为等式约束。这样一来，原问题就变为：
<span class="math display">\[\text{最小化}\;f(x),\qquad
x\;\text{满足}\;\begin{cases}
E_i(x)=0:\quad i\in\mathcal E,\\
I_j(x)-s_j=0:\quad j\in\mathcal I,\\
s_j\geqslant0:\quad j\in\mathcal I,
\end{cases}\]</span> 然后考虑等式约束的增广拉格朗日函数： <span
class="math display">\[\begin{align*}
L(x,s,\lambda,\sigma)=&amp;\;f(x)-\sum_{i\in\mathcal
E}\lambda_iE_i(x)-\sum_{j\in\mathcal I}\lambda_j[I_j(x)-s_j]\\
&amp;+\sigma\sum_{i\in\mathcal E}[E_i(x)]^2+\sigma\sum_{j\in\mathcal
I}[I_j(x)-s_j]^2
\end{align*}\]</span> 与等式约束情形类似，增广拉格朗日函数方法就是在给定
<span class="math inline">\(\lambda_k,\sigma_k\)</span> 时，找出 <span
class="math inline">\(L(x,s,\lambda_k,\sigma_k)\)</span> 在 <span
class="math inline">\(s_j\geqslant0\)</span> 时的最优点 <span
class="math inline">\((x_k,s_k)\)</span>，然后根据 <span
class="math inline">\((x_k,s_k)\)</span> 调整 <span
class="math inline">\(\lambda,\sigma\)</span> 进入下一个循环。</p>
<p>相较于等式约束情形，不等式约束的复杂之处是：要在 <span
class="math inline">\(s_j\geqslant0\)</span> 时求解 <span
class="math inline">\(L(x,s,\lambda_k,\sigma_k)\)</span>
的最小值。但非常幸运的是 <span
class="math inline">\(L(x,s,\lambda,\sigma)\)</span> 是一个关于 <span
class="math inline">\(s\)</span> 的二次函数，其极小值在 <span
class="math display">\[s_j(x,\lambda,\sigma)=\max\left\lbrace\dfrac{2\sigma
I_j(x)-\lambda_j}{2\sigma},0\right\rbrace=\max\left\lbrace
I_j(x)-\dfrac{\lambda_j}{2\sigma},0\right\rbrace.\]</span> 处取得。</p>
<p>由于 <span class="math inline">\(I_j(x)-s_j=\min\left\lbrace
\lambda_j/(2\sigma)
,I_j(x)\right\rbrace\)</span>，增广拉格朗日函数就成为： <span
class="math display">\[\begin{align*}
L(x,\lambda,\sigma) =&amp;\; f(x)-\sum_{i\in\mathcal
E}\lambda_iE_i(x)+\sigma\sum_{i\in\mathcal E}[E_i(x)]^2\\
&amp;+\sum_{i\in\mathcal I}\begin{cases}
-\lambda_jI_j(x)+\sigma[I_j(x)]^2,&amp;\quad\text{if}\quad
I_j(x)\leqslant\lambda_j/2\sigma,\\
-\lambda_j^2/(4\sigma),&amp;\quad\text{if}\quad
I_j(x)&gt;\lambda_j/2\sigma.
\end{cases}
\end{align*}\]</span></p>
<p>相应的求解算法为：</p>
<blockquote class="colorquote algorithm" ><ul>
<li>给定 <span class="math inline">\(\sigma_k\)</span>，<span
class="math inline">\(\lambda_k\)</span> 以及初值 <span
class="math inline">\(x_{k-1}\)</span>，用无约束优化算法求出以上增广拉格朗日函数
<span class="math inline">\(L(x,\lambda_k, \sigma_k)\)</span> 的极小值点
<span class="math inline">\(x_{k}\)</span>。</li>
<li>对于等式约束 <span class="math inline">\(i\in\mathcal E\)</span>，取
<span class="math inline">\(\lambda_{k+1,i} = \lambda_{k,i}-2\sigma_k
E(x_k)\)</span>。</li>
<li>对不不等式约束 <span class="math inline">\(j\in\mathcal
I\)</span>，取 <span
class="math inline">\(\lambda_{k+1,j}=\max\{\lambda_{k,j}-2\sigma_kI_j(x_k),0\}\)</span></li>
<li>按某种规则选取一个比 <span class="math inline">\(\sigma_k\)</span>
更大的 <span
class="math inline">\(\sigma_{k+1}\)</span>，回到第一步。</li>
</ul>
</blockquote>
<h2 id="障碍罚函数内点罚函数">障碍罚函数（内点罚函数）</h2>
<p>内点罚函数或障碍罚函数只能用于处理不等式约束，并且只能以内点即可行区域内的点为初值。内点罚函数的一般形式为：
<span class="math display">\[B(x,\sigma):=f(x)+\dfrac1\sigma\cdot
h[I(x)],\]</span> 其中 <span class="math inline">\(h[I(x)]\)</span>
在所有 <span class="math inline">\(I(x)\)</span> 都大于 <span
class="math inline">\(0\)</span> 时取有限值，对每一个 <span
class="math inline">\(I_j(x)\)</span> 都是单调递减的，并在任意一个 <span
class="math inline">\(I_j(x)\)</span> 趋于 <span
class="math inline">\(0\)</span> 时趋于无穷大。</p>
<p>不难看出，用内点罚函数产生求解序列时，罚函数总是能够阻碍这一序列跳出可行区域。因此内点罚函数方法产生的序列从可行区域内部趋于最优解，这一点与外点罚函数相反。</p>
<p>当 <span class="math inline">\(\sigma\rightarrow\infty\)</span>
时，内点罚函数对 <span class="math inline">\(B(x,\sigma)\)</span>
的贡献将很小，此时 <span class="math inline">\(B(x,\sigma)\)</span>
的最优解将与 <span class="math inline">\(f(x)\)</span>
的最优解相同。与外点罚函数相似的是，较大的 <span
class="math inline">\(\sigma\)</span>
会带来数值上的困难，因此人们也会采用逐渐增加 <span
class="math inline">\(\sigma\)</span> 的方式：</p>
<blockquote class="colorquote algorithm" ><ul>
<li>给定 <span class="math inline">\(\sigma_k\)</span> 以及初值 <span
class="math inline">\(x_{k-1}\)</span>，用无约束优化算法求出 <span
class="math inline">\(B(x,\sigma_k)\)</span> 的极小值点 <span
class="math inline">\(x_{k}\)</span>。</li>
<li>按某种规则选取一个比 <span class="math inline">\(\sigma_k\)</span>
更大的 <span
class="math inline">\(\sigma_{k+1}\)</span>，回到上一步。</li>
</ul>
</blockquote>
<p>与外点罚函数类似，我们也可以证明：只要原问题有可行点，即存在一个点使得所有约束都得以满足，并且
<span class="math inline">\(k\rightarrow\infty\)</span> 时 <span
class="math inline">\(\sigma_k\rightarrow\infty\)</span>，那么以上算法产生的序列就会收敛到原问题的最优解
<span class="math inline">\(x^\ast\)</span> 上。并且在收敛过程中，序列
<span class="math inline">\(f(x_k)\)</span> 随 <span
class="math inline">\(k\)</span> 的增加而逐渐下降。</p>
<div class='spoiler collapsed'>
    <div class='spoiler-title'>
        证明
    </div>
    <div class='spoiler-content'>
        <p>我们用 <span class="math inline">\(x(\sigma)\)</span> 表示 <span
class="math inline">\(B(x,\sigma)\)</span> 的最小值点。因此以上算法中
<span class="math inline">\(x_k=x(\sigma_k)\)</span>。</p>
<p>为了证明 <span class="math inline">\(x_k\)</span>
能够收敛于最优解，我们需要一个小的引理，这个小的引理与讨论外点罚函数时遇到的小引理很相似。</p>
<hr />
<p>这个引理是： <span
class="math inline">\(\sigma_2&gt;\sigma_1\)</span> 时有 <span
class="math display">\[f(x(\sigma_2))\leqslant f(x(\sigma_1)),\quad
h[I(x(\sigma_2))]\geqslant h[I(x(\sigma_1))].\]</span></p>
<p>证明如下。首先： <span class="math display">\[\begin{align*}
f(x(\sigma_1))+\dfrac{1}{\sigma_1}h[I(x(\sigma_1))]&amp;\leqslant
f(x(\sigma_2))+\dfrac{1}{\sigma_1}h[I(x(\sigma_2))],\\
f(x(\sigma_2))+\dfrac{1}{\sigma_2}h[I(x(\sigma_2))]&amp;\leqslant
f(x(\sigma_1))+\dfrac{1}{\sigma_2}h[I(x(\sigma_1))],\\
\end{align*}\]</span></p>
<p>因此： <span class="math display">\[\begin{align*}
f(x(\sigma_1))-\dfrac{1}{\sigma_1}h[I(x(\sigma_2))]&amp;\leqslant
f(x(\sigma_2))-\dfrac{1}{\sigma_1}h[I(x(\sigma_1))],\\
f(x(\sigma_2))+\dfrac{1}{\sigma_2}h[I(x(\sigma_2))]&amp;\leqslant
f(x(\sigma_1))+\dfrac{1}{\sigma_2}h[I(x(\sigma_1))],\\
\end{align*}\]</span></p>
<p>所以： <span
class="math display">\[\dfrac{\sigma_1-\sigma_2}{\sigma_1\sigma_2}h[I(x(\sigma_2))]\leqslant\dfrac{\sigma_1-\sigma_2}{\sigma_1\sigma_2}h[I(x(\sigma_1))]\]</span></p>
<p>这意味着 <span class="math display">\[h[I(x(\sigma_2))]\geqslant
h[I(x(\sigma_1))].\]</span></p>
<p>然后： <span class="math display">\[\begin{align*}
f(x(\sigma_2))&amp;\leqslant
f(x(\sigma_1))+\dfrac{1}{\sigma_2}h[I(x(\sigma_1))]-\dfrac{1}{\sigma_2}h[I(x(\sigma_2))]\leqslant
f(x(\sigma_1)).
\end{align*}\]</span></p>
<hr />
<p>现在，我们证明 <span class="math inline">\(x_k\)</span> 收敛于 <span
class="math inline">\(x^\ast\)</span>。由于 <span
class="math inline">\(f(x^\ast)\)</span> 应当是可行区域内的 <span
class="math inline">\(f(x)\)</span> 的下确界，因此对任意一个正实数 <span
class="math inline">\(\eta\)</span>，在可行区域内都存在一个点 <span
class="math inline">\(y_\eta\)</span> 使得： <span
class="math display">\[f(y_\eta)\leqslant f(x^\ast)+\eta/2.\]</span>
由于算法中 <span class="math inline">\(k\rightarrow\infty\)</span> 时
<span
class="math inline">\(\sigma_k\rightarrow\infty\)</span>，所以存在某个
<span class="math inline">\(m\)</span> 使得 <span
class="math inline">\(k\geqslant m\)</span> 都有： <span
class="math display">\[\sigma_k\geqslant\dfrac{2}{\eta}h[I(y_\eta)].\]</span>
根据 <span class="math inline">\(x_k\)</span> 的定义，有： <span
class="math display">\[f(x_k)+\dfrac{1}{\sigma_k}h[I(x_k)]\leqslant
f(y_\eta)+\dfrac{1}{\sigma_k}h[I(y_\eta)].\]</span> 因此，如果 <span
class="math inline">\(k\geqslant m\)</span> 就有： <span
class="math display">\[\begin{align*}
f(x_k)&amp;\leqslant
f(y_\eta)+\dfrac{1}{\sigma_k}h[I(y_\eta)]-\dfrac{1}{\sigma_k}h[I(x_k)]\\
&amp;\leqslant f(y_\eta)+\dfrac\eta2-\dfrac{1}{\sigma_k}h[I(x_m)]\\
&amp;\leqslant
f(x^\ast)+\dfrac\eta2+\dfrac\eta2-\dfrac{1}{\sigma_k}h[I(x_m)]\\
&amp;\leqslant f(x^\ast)+\eta-\dfrac{1}{\sigma_k}h[I(x_m)].
\end{align*}\]</span> 两边同时取 <span
class="math inline">\(k\rightarrow\infty\)</span> 的极限，就有： <span
class="math display">\[\lim_{k\rightarrow\infty}f(x_k)\leqslant
f(x^\ast)+\eta\]</span> 显然所有的 <span
class="math inline">\(f(x_k)\)</span> 都应该不低于 <span
class="math inline">\(f(x^\ast)\)</span>，由 <span
class="math inline">\(\eta\)</span> 的任意性及下确界的定义，我们可以知道
<span
class="math inline">\(\displaystyle\lim_{k\rightarrow\infty}f(x_k)=f(x^\ast)\)</span>，进而
<span class="math inline">\(x_k\)</span> 收敛于某个最优解。</p>

    </div>
</div>
<p>常用的内点罚函数有对数罚函数： <span
class="math display">\[B(x,\sigma) =
f(x)+\dfrac1\sigma\sum_{j\in\mathcal
I}\log\dfrac{1}{I_j(x)}.\]</span></p>
<p>以及倒数罚函数： <span class="math display">\[B(x,\sigma) =
f(x)+\dfrac1\sigma\sum_{j\in\mathcal I}\dfrac{1}{I_j(x)}.\]</span></p>
<h2 id="对数罚函数与内点法">对数罚函数与内点法</h2>
<p>我们可以通过引入松弛变量将约束优化问题 (<span
class="math inline">\(\ref{problem}\)</span>) 转化为如下形式： <span
class="math display">\[\begin{align*}
\text{最小化}\;f(x,s)=f(x),\qquad x,s\;\text{满足}
\begin{cases}
E_i(x)=0:&amp;\quad i\in\mathcal E\\
I_j(x)-s_j=0:&amp;\quad j\in\mathcal I\\
s_j\geqslant0:&amp;\quad j\in\mathcal I
\end{cases}.
\end{align*}\]</span> 这一问题的 KKT 条件为： <span
class="math display">\[\begin{align*}
\begin{cases}
&amp;\nabla f(x)-\displaystyle\sum_{i\in\mathcal E}\lambda_i\nabla
E_i(x)-\sum_{j\in\mathcal I}z_j\nabla I_j(x)=0,\\
&amp;z_js_j=0,\quad z_j\geqslant0,\quad s_j\geqslant0:\quad j\in\mathcal
I,\\[3.5mm]
&amp;I_j(x)=s_j:\quad j\in\mathcal I,\\[3.5mm]
&amp;E_i(x)=0:\quad i\in\mathcal E.
\end{cases}
\end{align*}\]</span> 内点法求解的是如下近似 KKT 条件： <span
class="math display">\[\begin{align*}
\begin{cases}
&amp;\nabla f(x)-\displaystyle\sum_{i\in\mathcal E}\lambda_i\nabla
E_i(x)-\sum_{j\in\mathcal I}z_j\nabla I_j(x)=0,\\
&amp;z_js_j=\mu&gt;0,\quad z_j\geqslant0,\quad s_j\geqslant0:\quad
j\in\mathcal I,\\[3.5mm]
&amp;I_j(x)=s_j:\quad j\in\mathcal I,\\[3.5mm]
&amp;E_i(x)=0:\quad i\in\mathcal E.
\end{cases}
\end{align*}\]</span></p>
<p>如果 <span class="math inline">\(\mu=0\)</span>，以上近似 KKT
条件就是约束优化问题的 KKT 条件。如果 <span
class="math inline">\(\mu&gt;0\)</span>，那么求解以上近似 KKT 条件得到的
<span class="math inline">\(z\)</span> 与 <span
class="math inline">\(s\)</span> 都是大于 <span
class="math inline">\(0\)</span> 的，而 <span
class="math inline">\(s&gt;0\)</span> 意味着所有 <span
class="math inline">\(I(x)\)</span> 都大于 <span
class="math inline">\(0\)</span>，所以以上近似 KKT
条件的解都是可行区域的内点。可以想象，只要选取一个收敛于 <span
class="math inline">\(0\)</span> 的序列 <span
class="math inline">\(\{\mu_k\}\)</span>，对每个 <span
class="math inline">\(\mu_k\)</span> 求解以上近似 KKT
条件，那么得到的内点就会趋近于约束优化问题的解，这就是内点法的思路。</p>
<p>这一内点法与对数罚函数密切相关。我们可以考虑如下优化问题： <span
class="math display">\[\begin{align*}
\text{最小化}\;f(x,s)=f(x)-\mu\sum_{j\in\mathcal I}\log s_j,\qquad
x\;\text{满足}
\begin{cases}
E_i(x)=0:\quad i\in\mathcal E\\
I_j(x)=s_j:\quad j\in\mathcal I
\end{cases}.
\end{align*}\]</span> 其中 <span
class="math inline">\(\mu&gt;0\)</span>。</p>
<p>这个问题的拉格朗日函数为： <span
class="math display">\[\begin{align*}
\mathcal L(x,s)= f(x)-\mu\sum_{j\in\mathcal I}\log
s_j-\sum_{i\in\mathcal E}\lambda_iE_i(x)-\sum_{j\in\mathcal
I}z_j[I_j(x)-s_j].
\end{align*}\]</span> 它的 KKT 条件为： <span
class="math display">\[\begin{align*}
\begin{cases}
&amp;\nabla f(x)-\displaystyle\sum_{i\in\mathcal E}\lambda_i\nabla
E_i(x)-\sum_{j\in\mathcal I}z_j\nabla I_j(x)=0,\\
&amp;-\mu\dfrac{1}{s_j}+z_j=0:\quad j\in\mathcal I,\\[3.5mm]
&amp;I_j(x)=s_j:\quad j\in\mathcal I,\\[3.5mm]
&amp;E_i(x)=0:\quad i\in\mathcal E.
\end{cases}
\end{align*}\]</span> 可以看到，这个问题的 KKT 条件与内点法求解的近似
KKT 条件是等价的，只在第二个方程上存在差距。</p>
<hr />
<h1 id="参考书籍">参考书籍</h1>
<ul>
<li>《非线性优化计算方法》 袁亚湘.<span
class="math inline">\(\quad\)</span>北京：科学出版社，2008.</li>
<li>《最优化理论与方法》 袁亚湘, 孙文瑜.<span
class="math inline">\(\quad\)</span>北京：科学出版社，1997.</li>
<li>《<a
target="_blank" rel="noopener" href="https://www.math.uci.edu/~qnie/Publications/NumericalOptimization.pdf">Numerical
Optimization (2rd Ed.)</a>》 Jorge Nocedal, Stephen J. Wright. Springer
New York, 2006.</li>
<li>《<a
target="_blank" rel="noopener" href="https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf">Convex
Optimization</a>》 Stephen Boyd, Lieven Vandenberghe. Cambridge:
Cambridge University Press, 2004.</li>
<li>《数值最优化方法》 高立.<span
class="math inline">\(\quad\)</span>北京：北京大学出版社，2014.</li>
<li>《<a
target="_blank" rel="noopener" href="http://faculty.bicmr.pku.edu.cn/~wenzw/optbook.html">最优化：建模、算法与理论</a>》
刘浩洋、户将、李勇锋、文再文.<span
class="math inline">\(\quad\)</span>北京：高等教育出版社，2020.</li>
<li>《非线性最优化计算方法》 张光澄主编.<span
class="math inline">\(\quad\)</span>北京：高等教育出版社，2005.</li>
<li><span class="math inline">\(\;\;\)</span><a
target="_blank" rel="noopener" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">scipy.optimize.minimize
的文档</a></li>
</ul>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
    </div>

    
    
    

    <footer class="post-footer">

        

    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-ghost"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">XMQ</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div><script color="0,0,255" opacity="0.5" zIndex="-1" count="99" src="https://cdn.jsdelivr.net/npm/canvas-nest.js@1/dist/canvas-nest.js"></script>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
